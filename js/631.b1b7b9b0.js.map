{"version":3,"file":"js/631.b1b7b9b0.js","mappings":"yYAUA,IAAMA,EAAa,CAAEC,MAAO,gBACtBC,EAAa,CAAED,MAAO,aACtBE,EAAa,CAAEF,MAAO,0BACtBG,EAAa,CACjBH,MAAO,UACPI,GAAI,YAEAC,EAAa,CAAEL,MAAO,mBACtBM,EAAa,CACjBN,MAAO,UACPI,GAAI,WAEAG,EAAa,CAAEP,MAAO,mBACtBQ,EAAa,CACjBR,MAAO,UACPI,GAAI,kBAEAK,EAAa,CAAET,MAAO,mBACtBU,EAAc,CAAEV,MAAO,cACvBW,EAAc,CAAEX,MAAO,cACvBY,EAAc,CAAEZ,MAAO,cACvBa,EAAc,CAClBb,MAAO,UACPI,GAAI,eAEAU,EAAc,CAAEd,MAAO,mBAG7B,SAA4Be,EAAAA,EAAAA,IAAiB,CAC3CC,OAAQ,cACRC,MAAK,SAACC,GCyQN,IAAMC,EAAY,CAChB,CACEC,MAAO,qBACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,kBACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,aACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,oBACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,eACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,aACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,aACPC,KAAM,cACNC,WAAY,SAIVC,EAAe,CACnB,CAAEH,MAAO,SAAUC,KAAM,cAAeC,WAAY,QACpD,CAAEF,MAAO,8BAA+BC,KAAM,cAAeC,WAAY,OACzE,CAAEF,MAAO,eAAgBC,KAAM,cAAeC,WAAY,KAC1D,CAAEF,MAAO,gBAAiBC,KAAM,eAAgBC,WAAY,QAC5D,CAAEF,MAAO,qCAAsCC,KAAM,cAAeC,WAAY,QAChF,CAAEF,MAAO,sBAAuBC,KAAM,cAAeC,WAAY,KACjE,CAAEF,MAAO,eAAgBC,KAAM,eAAgBC,WAAY,QAC3D,CAAEF,MAAO,oCAAqCC,KAAM,eAAgBC,WAAY,QAChF,CAAEF,MAAO,qBAAsBC,KAAM,cAAeC,WAAY,MAG5DE,EAAkB,SAACC,GACvB,IAAMC,EAAUC,SAASC,eAAeH,GACpCC,GACFA,EAAQG,eAAe,CAAEC,SAAU,UAEvC,EDlQF,OAAO,SAACC,EAAUC,GAChB,IAAMC,GAA0BC,EAAAA,EAAAA,IAAkB,gBAC5CC,GAAqBD,EAAAA,EAAAA,IAAkB,WACvCE,GAAoBF,EAAAA,EAAAA,IAAkB,UACtCG,GAAoBH,EAAAA,EAAAA,IAAkB,UACtCI,GAA6BJ,EAAAA,EAAAA,IAAkB,mBAC/CK,GAAsBL,EAAAA,EAAAA,IAAkB,YAE9C,OAAQM,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoB,MAAO1C,EAAY,EAC3D2C,EAAAA,EAAAA,IAAaP,EAAoB,CAC/BQ,KAAM,aACN,mBAAoB,mBACpB,aAAc,OACd,oBAAqB,QACpB,CACDC,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaT,EAAyB,CAAEa,MAAO,KAAO,CACpDF,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDe,EAAAA,EAAAA,IAAoB,OAAQ,CAAEC,MAAO,CAAC,cAAc,QAAU,SAAU,IACxE,IACFC,EAAG,KAELP,EAAAA,EAAAA,IAAaT,EAAyB,CACpCiB,QAASlB,EAAO,KAAOA,EAAO,GAAK,SAACmB,GAAW,OAAM3B,EAAgB,WAAW,IAC/E,CACDoB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDoB,EAAAA,EAAAA,IAAiB,aACjB,IACFH,EAAG,KAELP,EAAAA,EAAAA,IAAaT,EAAyB,CACpCiB,QAASlB,EAAO,KAAOA,EAAO,GAAK,SAACmB,GAAW,OAAM3B,EAAgB,UAAU,IAC9E,CACDoB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDoB,EAAAA,EAAAA,IAAiB,yCACjB,IACFH,EAAG,KAELP,EAAAA,EAAAA,IAAaT,EAAyB,CACpCiB,QAASlB,EAAO,KAAOA,EAAO,GAAK,SAACmB,GAAW,OAAM3B,EAAgB,iBAAiB,IACrF,CACDoB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDoB,EAAAA,EAAAA,IAAiB,mBACjB,IACFH,EAAG,KAELP,EAAAA,EAAAA,IAAaT,EAAyB,CACpCiB,QAASlB,EAAO,KAAOA,EAAO,GAAK,SAACmB,GAAW,OAAM3B,EAAgB,cAAc,IAClF,CACDoB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDoB,EAAAA,EAAAA,IAAiB,gBACjB,IACFH,EAAG,KAELP,EAAAA,EAAAA,IAAaT,EAAyB,CACpCiB,QAASlB,EAAO,KAAOA,EAAO,GAAK,SAACmB,GAAW,OAAM3B,EAAgB,YAAY,IAChF,CACDoB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDoB,EAAAA,EAAAA,IAAiB,cACjB,IACFH,EAAG,IAEN,IACDA,EAAG,IAELjB,EAAO,MAAQA,EAAO,KAAMqB,EAAAA,EAAAA,IAAmB,w+CAA+gD,KAC9jDN,EAAAA,EAAAA,IAAoB,MAAO9C,EAAY,EACrCyC,EAAAA,EAAAA,IAAaL,EAAmB,CAC9BiB,QAAS,SACTtD,MAAO,iBACN,CACD4C,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAC9BmB,GAAI,GACJC,GAAI,GACJC,GAAI,EACJC,GAAI,EACJ1D,MAAO,cACN,CACD4C,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBY,IAAKC,EACLC,IAAK,qBACL7D,MAAO,8BACN,MAAO,IACV,IACFiD,EAAG,KAELP,EAAAA,EAAAA,IAAaN,EAAmB,CAC9BmB,GAAI,GACJC,GAAI,GACJC,GAAI,EACJC,GAAI,EACJ1D,MAAO,cACN,CACD4C,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBY,IAAKC,EACLC,IAAK,qBACL7D,MAAO,8BACN,MAAO,IACV,IACFiD,EAAG,IAEN,IACDA,EAAG,OAGPF,EAAAA,EAAAA,IAAoB,MAAO7C,EAAY,EACrCwC,EAAAA,EAAAA,IAAaL,EAAmB,CAAEiB,QAAS,UAAY,CACrDV,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBE,EAAAA,EAAAA,IAAoB,MAAO5C,EAAY,CACrC6B,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAE/C,MAAO,iBAAmB,cACtD,KACJ+C,EAAAA,EAAAA,IAAoB,MAAO1C,EAAY,EACrCqC,EAAAA,EAAAA,IAAaL,EAAmB,CAAE0B,OAAQ,IAAM,CAC9CnB,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,KACxCpB,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,g+BAAi+B,IAChgC,IACFE,EAAG,KAELP,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBY,IAAKK,EACLH,IAAK,WACL7D,MAAO,mCACN,MAAO,IACV,IACFiD,EAAG,IAEN,IACDA,EAAG,SAITF,EAAAA,EAAAA,IAAoB,MAAOzC,EAAY,CACrC0B,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAE/C,MAAO,iBAAmB,0CACtD,KACJ+C,EAAAA,EAAAA,IAAoB,MAAOxC,EAAY,CACrCyB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,yTAA0T,IACrXf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,wBAAyB,IACrFf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,mGAAoG,KAC/JL,EAAAA,EAAAA,IAAaH,EAAqB,CAChC0B,KAAM9C,EACN6B,MAAO,CAAC,MAAQ,QAChBkB,OAAQ,IACP,CACDtB,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,QACNC,MAAO,QACPC,MAAO,YAET3B,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,OACNC,MAAO,mBACPC,MAAO,YAET3B,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,aACNC,MAAO,UACPC,MAAO,UACN,CACDzB,SAASC,EAAAA,EAAAA,KAAS,SAACyB,GAAK,MAAK,EAC3BlB,EAAAA,EAAAA,KAAiBmB,EAAAA,EAAAA,IAAiBD,EAAME,IAAIlD,YAAa,GAC1D,IACD2B,EAAG,IAEN,IACDA,EAAG,IAELjB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,CAAE/C,MAAO,iBAAmB,+EAAgF,IACjKgC,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAE/C,MAAO,mBAAqB,EACnF+C,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCK,EAAAA,EAAAA,IAAiB,4JACf,SAGRL,EAAAA,EAAAA,IAAoB,MAAOvC,EAAY,CACrCwB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAE/C,MAAO,iBAAmB,oBACtD,KACJ+C,EAAAA,EAAAA,IAAoB,MAAOtC,EAAY,CACrCuB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,2HAA4H,KACvLA,EAAAA,EAAAA,IAAoB,MAAOrC,EAAa,EACtCgC,EAAAA,EAAAA,IAAaL,EAAmB,CAAE0B,OAAQ,IAAM,CAC9CnB,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,+BAAgC,IAChEA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,iJAAkJ,IACjLA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,0EAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,sHAC9B,IACJ,IACFE,EAAG,KAELP,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBY,IAAKc,EACLZ,IAAK,+BACL7D,MAAO,gBACN,MAAO,IACV,IACFiD,EAAG,IAEN,IACDA,EAAG,IAELjB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAE/C,MAAO,mBAAqB,EACnF+C,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCK,EAAAA,EAAAA,IAAiB,mNACf,OAENL,EAAAA,EAAAA,IAAoB,MAAOpC,EAAa,EACtC+B,EAAAA,EAAAA,IAAaL,EAAmB,CAAE0B,OAAQ,IAAM,CAC9CnB,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,8CAA+C,IAC/EA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,wJAAyJ,IACxLA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,gGAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,uFAC9B,IACJ,IACFE,EAAG,KAELP,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,KACxCpB,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBY,IAAKe,EACLb,IAAK,6BACL7D,MAAO,gBACN,MAAO,IACV,IACFiD,EAAG,IAEN,IACDA,EAAG,IAELjB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAE/C,MAAO,mBAAqB,EACnF+C,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCK,EAAAA,EAAAA,IAAiB,oHACf,OAENL,EAAAA,EAAAA,IAAoB,MAAOnC,EAAa,EACtC8B,EAAAA,EAAAA,IAAaL,EAAmB,CAAE0B,OAAQ,IAAM,CAC9CnB,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,yCAA0C,IAC1EA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,kHAAmH,IAClJA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,SAAU,KAAM,kBACpCK,EAAAA,EAAAA,IAAiB,2FAEnBL,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,SAAU,KAAM,wBACpCK,EAAAA,EAAAA,IAAiB,oEAEnBL,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,SAAU,KAAM,wBACpCK,EAAAA,EAAAA,IAAiB,2DAEjB,IACJ,IACFH,EAAG,KAELP,EAAAA,EAAAA,IAAaN,EAAmB,CAAE0B,KAAM,IAAM,CAC5ClB,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBY,IAAKgB,EACLd,IAAK,yBACL7D,MAAO,gBACN,MAAO,IACV,IACFiD,EAAG,IAEN,IACDA,EAAG,IAELjB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAE/C,MAAO,mBAAqB,EACnF+C,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCK,EAAAA,EAAAA,IAAiB,gXACf,WAIVL,EAAAA,EAAAA,IAAoB,MAAOlC,EAAa,CACtCmB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAE/C,MAAO,iBAAmB,iBACtD,KACJ+C,EAAAA,EAAAA,IAAoB,MAAOjC,EAAa,CACtCkB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,iMAAkM,IAC7Pf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEC,MAAO,CAAC,aAAa,WAAa,EACzFD,EAAAA,EAAAA,IAAoB,MAAO,CACzBY,IAAKiB,EACLf,IAAK,qBACL7D,MAAO,mBACPgD,MAAO,CAAC,MAAQ,WAEhB,IACJhB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAE/C,MAAO,iBAAmB,EACjF+C,EAAAA,EAAAA,IAAoB,KAAM,KAAM,0BAChCA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,8NAC7B,IACJf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAE/C,MAAO,iBAAmB,EACjF+C,EAAAA,EAAAA,IAAoB,KAAM,KAAM,6CAChCA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,kMAC7B,IACJf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,eAAgB,IAC5Ef,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,sFAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,kDAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,2EAC9B,KACJL,EAAAA,EAAAA,IAAaH,EAAqB,CAChC0B,KAAM1C,EACNyB,MAAO,CAAC,MAAQ,QAChBkB,OAAQ,IACP,CACDtB,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,QACNC,MAAO,QACPC,MAAO,YAET3B,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,OACNC,MAAO,mBACPC,MAAO,YAET3B,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,aACNC,MAAO,UACPC,MAAO,UACN,CACDzB,SAASC,EAAAA,EAAAA,KAAS,SAACyB,GAAK,MAAK,EAC3BlB,EAAAA,EAAAA,KAAiBmB,EAAAA,EAAAA,IAAiBD,EAAME,IAAIlD,YAAa,GAC1D,IACD2B,EAAG,IAEN,IACDA,EAAG,IAELjB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,CAAE/C,MAAO,iBAAmB,mFAAoF,QAGzKgC,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CACrD/C,MAAO,UACPI,GAAI,aACH,EACD2C,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,OAAQ,CAAE/C,MAAO,iBAAmB,gBAE1D+C,EAAAA,EAAAA,IAAoB,MAAO,CAAE/C,MAAO,mBAAqB,EACvD+C,EAAAA,EAAAA,IAAoB,IAAK,KAAM,8DAC/BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,IAAK,CACvB8B,KAAM,6CACNC,OAAQ,UACP,wBAIP,IACL,IACD7B,EAAG,IAEN,IACDA,EAAG,OAIX,CACA,I,eEreA,MAAM8B,GAA2B,OAAgB,EAAQ,CAAC,CAAC,YAAY,qBAEvE,G","sources":["webpack://X-ISC/./src/views/ProjectView.vue?cc76","webpack://X-ISC/./src/views/ProjectView.vue","webpack://X-ISC/./src/views/ProjectView.vue?09a1"],"sourcesContent":["import { defineComponent as _defineComponent } from 'vue'\nimport { createElementVNode as _createElementVNode, resolveComponent as _resolveComponent, withCtx as _withCtx, createVNode as _createVNode, createTextVNode as _createTextVNode, toDisplayString as _toDisplayString, createStaticVNode as _createStaticVNode, openBlock as _openBlock, createElementBlock as _createElementBlock } from \"vue\"\nimport _imports_0 from '@/figures/output.gif'\nimport _imports_1 from '@/figures/overviewf3.png'\nimport _imports_2 from '@/figures/internal_confidence.png'\nimport _imports_3 from '@/figures/case.png'\nimport _imports_4 from '@/figures/humanCognitiveBiasf.png'\nimport _imports_5 from '@/figures/mergedMitigation2.png'\n\n\nconst _hoisted_1 = { class: \"project-page\" }\nconst _hoisted_2 = { class: \"container\" }\nconst _hoisted_3 = { class: \"container main-content\" }\nconst _hoisted_4 = {\n  class: \"section\",\n  id: \"abstract\"\n}\nconst _hoisted_5 = { class: \"section-content\" }\nconst _hoisted_6 = {\n  class: \"section\",\n  id: \"failure\"\n}\nconst _hoisted_7 = { class: \"section-content\" }\nconst _hoisted_8 = {\n  class: \"section\",\n  id: \"interpretation\"\n}\nconst _hoisted_9 = { class: \"section-content\" }\nconst _hoisted_10 = { class: \"method-box\" }\nconst _hoisted_11 = { class: \"method-box\" }\nconst _hoisted_12 = { class: \"method-box\" }\nconst _hoisted_13 = {\n  class: \"section\",\n  id: \"alleviation\"\n}\nconst _hoisted_14 = { class: \"section-content\" }\n\n\nexport default /*@__PURE__*/_defineComponent({\n  __name: 'ProjectView',\n  setup(__props) {\n\n  // No additional scripts needed for static content\n  \n  // Sample Data for Tables\n  const boolqData = [\n    { \n      model: 'ChatGPT o1-preview', \n      acc1: '78.7 (↓4.9)', \n      overturned: '13.2' \n    },\n    { \n      model: 'ChatGPT o1-mini', \n      acc1: '74.1 (↓4.2)', \n      overturned: '15.6' \n    },\n    { \n      model: 'ChatGPT 4o', \n      acc1: '79.2 (↓4.9)', \n      overturned: '11.3' \n    },\n    { \n      model: 'ChatGPT 3.5-turbo', \n      acc1: '62.5 (↓12.1)', \n      overturned: '34.0' \n    },\n    { \n      model: 'Llama-3.1-8B', \n      acc1: '49.2 (↓20.4)', \n      overturned: '58.8' \n    },\n    { \n      model: 'Llama-3-8B', \n      acc1: '50.1 (↓20.3)', \n      overturned: '58.2' \n    },\n    { \n      model: 'Llama-2-7B', \n      acc1: '52.8 (↓8.7)', \n      overturned: '26.5' \n    }\n  ];\n  \n  const mitigateData = [\n    { model: 'GPT-4o', acc1: '79.2 (↓4.9)', overturned: '11.3' },\n    { model: 'GPT-4o + Question repeating', acc1: '83.6 (↓0.5)', overturned: '6.0' },\n    { model: 'GPT-4o + SFT', acc1: '87.7 (↑4.1)', overturned: '0' },\n    { model: 'GPT-3.5-turbo', acc1: '62.5 (↓12.1)', overturned: '34.0' },\n    { model: 'GPT-3.5-turbo + Question repeating', acc1: '67.4 (↓7.2)', overturned: '23.1' },\n    { model: 'GPT-3.5-turbo + SFT', acc1: '76.2 (↑1.6)', overturned: '0' },\n    { model: 'Llama-3.1-8B', acc1: '49.2 (↓20.4)', overturned: '58.8' },\n    { model: 'Llama-3.1-8B + Question repeating', acc1: '52.4 (↓17.2)', overturned: '52.8' },\n    { model: 'Llama-3.1-8B + SFT', acc1: '70.3 (↑0.7)', overturned: '0' }\n  ];\n  \n  const scrollToSection = (sectionId: string) => {\n    const element = document.getElementById(sectionId);\n    if (element) {\n      element.scrollIntoView({ behavior: 'smooth' });\n    }\n  };\n  \nreturn (_ctx: any,_cache: any) => {\n  const _component_el_menu_item = _resolveComponent(\"el-menu-item\")!\n  const _component_el_menu = _resolveComponent(\"el-menu\")!\n  const _component_el_col = _resolveComponent(\"el-col\")!\n  const _component_el_row = _resolveComponent(\"el-row\")!\n  const _component_el_table_column = _resolveComponent(\"el-table-column\")!\n  const _component_el_table = _resolveComponent(\"el-table\")!\n\n  return (_openBlock(), _createElementBlock(\"div\", _hoisted_1, [\n    _createVNode(_component_el_menu, {\n      mode: \"horizontal\",\n      \"background-color\": 'rgb(140, 21, 21)',\n      \"text-color\": \"#fff\",\n      \"active-text-color\": \"#fff\"\n    }, {\n      default: _withCtx(() => [\n        _createVNode(_component_el_menu_item, { index: \"/\" }, {\n          default: _withCtx(() => _cache[5] || (_cache[5] = [\n            _createElementVNode(\"span\", { style: {\"font-weight\":\"800\"} }, \"X-ISC\", -1)\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[0] || (_cache[0] = ($event: any) => (scrollToSection('abstract')))\n        }, {\n          default: _withCtx(() => _cache[6] || (_cache[6] = [\n            _createTextVNode(\"Abstract\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[1] || (_cache[1] = ($event: any) => (scrollToSection('failure')))\n        }, {\n          default: _withCtx(() => _cache[7] || (_cache[7] = [\n            _createTextVNode(\"Failure of Intrinsic Self-Correction\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[2] || (_cache[2] = ($event: any) => (scrollToSection('interpretation')))\n        }, {\n          default: _withCtx(() => _cache[8] || (_cache[8] = [\n            _createTextVNode(\"Interpretation\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[3] || (_cache[3] = ($event: any) => (scrollToSection('alleviation')))\n        }, {\n          default: _withCtx(() => _cache[9] || (_cache[9] = [\n            _createTextVNode(\"Alleviation\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[4] || (_cache[4] = ($event: any) => (scrollToSection('resources')))\n        }, {\n          default: _withCtx(() => _cache[10] || (_cache[10] = [\n            _createTextVNode(\"Resources\")\n          ])),\n          _: 1\n        })\n      ]),\n      _: 1\n    }),\n    _cache[42] || (_cache[42] = _createStaticVNode(\"<div class=\\\"container header\\\" data-v-2b1ff5f8><h2 class=\\\"title\\\" data-v-2b1ff5f8>Understanding the Dark Side of LLMs&#39; Intrinsic Self-Correction</h2><h4 class=\\\"subtitle\\\" data-v-2b1ff5f8><span class=\\\"underline\\\" data-v-2b1ff5f8>Ex</span>plaining <span class=\\\"underline\\\" data-v-2b1ff5f8>I</span>ntrinsic <span class=\\\"underline\\\" data-v-2b1ff5f8>S</span>elf-<span class=\\\"underline\\\" data-v-2b1ff5f8>C</span>orrection (X-ISC) </h4><div class=\\\"author-info\\\" data-v-2b1ff5f8><span data-v-2b1ff5f8>Anonymous submission</span></div><div class=\\\"github-link-container\\\" data-v-2b1ff5f8><a href=\\\"https://anonymous.4open.science/r/SC-15FB/\\\" class=\\\"github-button\\\" target=\\\"_blank\\\" data-v-2b1ff5f8><i class=\\\"github-icon\\\" data-v-2b1ff5f8><svg xmlns=\\\"http://www.w3.org/2000/svg\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" viewBox=\\\"0 0 16 16\\\" data-v-2b1ff5f8><path d=\\\"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z\\\" data-v-2b1ff5f8></path></svg></i><span data-v-2b1ff5f8>Project Code</span></a></div></div>\", 1)),\n    _createElementVNode(\"div\", _hoisted_2, [\n      _createVNode(_component_el_row, {\n        justify: \"center\",\n        class: \"gif-container\"\n      }, {\n        default: _withCtx(() => [\n          _createVNode(_component_el_col, {\n            xs: 20,\n            sm: 16,\n            md: 8,\n            lg: 8,\n            class: \"gif-column\"\n          }, {\n            default: _withCtx(() => _cache[11] || (_cache[11] = [\n              _createElementVNode(\"img\", {\n                src: _imports_0,\n                alt: \"Output Animation 1\",\n                class: \"responsive-image gif-image\"\n              }, null, -1)\n            ])),\n            _: 1\n          }),\n          _createVNode(_component_el_col, {\n            xs: 20,\n            sm: 16,\n            md: 8,\n            lg: 8,\n            class: \"gif-column\"\n          }, {\n            default: _withCtx(() => _cache[12] || (_cache[12] = [\n              _createElementVNode(\"img\", {\n                src: _imports_0,\n                alt: \"Output Animation 2\",\n                class: \"responsive-image gif-image\"\n              }, null, -1)\n            ])),\n            _: 1\n          })\n        ]),\n        _: 1\n      })\n    ]),\n    _createElementVNode(\"div\", _hoisted_3, [\n      _createVNode(_component_el_row, { justify: \"center\" }, {\n        default: _withCtx(() => [\n          _createVNode(_component_el_col, { span: 20 }, {\n            default: _withCtx(() => [\n              _createElementVNode(\"div\", _hoisted_4, [\n                _cache[15] || (_cache[15] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Abstract\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_5, [\n                  _createVNode(_component_el_row, { gutter: 20 }, {\n                    default: _withCtx(() => [\n                      _createVNode(_component_el_col, { span: 1 }),\n                      _createVNode(_component_el_col, { span: 11 }, {\n                        default: _withCtx(() => _cache[13] || (_cache[13] = [\n                          _createElementVNode(\"p\", null, \" Intrinsic self-correction was proposed to improve LLMs' responses via feedback solely based on their inherent capability. However, recent works show that LLMs' intrinsic self-correction fails without oracle labels as feedback. In this paper, we aim to interpret LLMs' intrinsic self-correction for different tasks, especially for those failure cases? By including one simple task and three complex tasks with state-of-the-art (SOTA) LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B, and 3.1-8B), we design interpretation methods to reveal the dark side of SOTA LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1) cause LLMs to waver both intermedia and final answers and lead to prompt bias on simple factual questions; (2) introduce human-like cognitive bias on complex tasks. In light of our findings, we also provide two simple, low-cost, yet effective strategies for alleviation: question repeating and supervised fine-tuning. \", -1)\n                        ])),\n                        _: 1\n                      }),\n                      _createVNode(_component_el_col, { span: 10 }, {\n                        default: _withCtx(() => _cache[14] || (_cache[14] = [\n                          _createElementVNode(\"img\", {\n                            src: _imports_1,\n                            alt: \"Overview\",\n                            class: \"responsive-image abstract-image\"\n                          }, null, -1)\n                        ])),\n                        _: 1\n                      })\n                    ]),\n                    _: 1\n                  })\n                ])\n              ]),\n              _createElementVNode(\"div\", _hoisted_6, [\n                _cache[21] || (_cache[21] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Failure of Intrinsic Self-Correction\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_7, [\n                  _cache[16] || (_cache[16] = _createElementVNode(\"p\", null, \" Intrinsic self-correction mechanisms in state-of-the-art LLMs were expected to enhance performance by refining responses based solely on the model's inherent capabilities. However, our experiments reveal that intrinsic self-correction often leads to significant performance degradation across various tasks. \", -1)),\n                  _cache[17] || (_cache[17] = _createElementVNode(\"h4\", null, \"Experimental Results\", -1)),\n                  _cache[18] || (_cache[18] = _createElementVNode(\"p\", null, \"Below are the key experimental results demonstrating the failures of intrinsic self-correction:\", -1)),\n                  _createVNode(_component_el_table, {\n                    data: boolqData,\n                    style: {\"width\":\"100%\"},\n                    border: \"\"\n                  }, {\n                    default: _withCtx(() => [\n                      _createVNode(_component_el_table_column, {\n                        prop: \"model\",\n                        label: \"Model\",\n                        align: \"center\"\n                      }),\n                      _createVNode(_component_el_table_column, {\n                        prop: \"acc1\",\n                        label: \"ACC₁ (↓ΔACC) (%)\",\n                        align: \"center\"\n                      }),\n                      _createVNode(_component_el_table_column, {\n                        prop: \"overturned\",\n                        label: \"✓→✗ (%)\",\n                        align: \"center\"\n                      }, {\n                        default: _withCtx((scope) => [\n                          _createTextVNode(_toDisplayString(scope.row.overturned), 1)\n                        ]),\n                        _: 1\n                      })\n                    ]),\n                    _: 1\n                  }),\n                  _cache[19] || (_cache[19] = _createElementVNode(\"p\", { class: \"table-caption\" }, \"Table 1: Self-correction performance on the Yes/No question answering task.\", -1)),\n                  _cache[20] || (_cache[20] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                    _createElementVNode(\"strong\", null, \"Observation 1:\"),\n                    _createTextVNode(\" Self-correction can fail in diverse tasks. For SOTA LLMs, self-correction failures are reduced but not solved. They are even worse in certain tasks. \")\n                  ], -1))\n                ])\n              ]),\n              _createElementVNode(\"div\", _hoisted_8, [\n                _cache[32] || (_cache[32] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Interpretation\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_9, [\n                  _cache[31] || (_cache[31] = _createElementVNode(\"p\", null, \" We propose three interpretation methods to understand how and why intrinsic self-correction fails in different tasks: \", -1)),\n                  _createElementVNode(\"div\", _hoisted_10, [\n                    _createVNode(_component_el_row, { gutter: 20 }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_col, { span: 12 }, {\n                          default: _withCtx(() => _cache[22] || (_cache[22] = [\n                            _createElementVNode(\"h4\", null, \"1. Internal Answer Wavering\", -1),\n                            _createElementVNode(\"p\", null, \" We analyze LLMs' internal token representations at each layer to track how confidence in different answers evolves. Our findings show that: \", -1),\n                            _createElementVNode(\"ul\", null, [\n                              _createElementVNode(\"li\", null, \"Self-correction increases internal answer wavering from 8.3% to 14.1%\"),\n                              _createElementVNode(\"li\", null, \"Prompting with \\\"Are you sure?\\\" produces nearly identical confidence patterns as directly stating \\\"You are wrong\\\"\")\n                            ], -1)\n                          ])),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_col, { span: 12 }, {\n                          default: _withCtx(() => _cache[23] || (_cache[23] = [\n                            _createElementVNode(\"img\", {\n                              src: _imports_2,\n                              alt: \"Internal Confidence Analysis\",\n                              class: \"method-image\"\n                            }, null, -1)\n                          ])),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }),\n                    _cache[24] || (_cache[24] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                      _createElementVNode(\"strong\", null, \"Observation 2:\"),\n                      _createTextVNode(\" Self-correction causes internal answer wavering, which could further lead to wrong final answers. Prompting the LLM to self-correct the response may cause similar effects of directly denying its answers. \")\n                    ], -1))\n                  ]),\n                  _createElementVNode(\"div\", _hoisted_11, [\n                    _createVNode(_component_el_row, { gutter: 20 }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_col, { span: 11 }, {\n                          default: _withCtx(() => _cache[25] || (_cache[25] = [\n                            _createElementVNode(\"h4\", null, \"2. Token Attribution Analysis: Prompt Bias\", -1),\n                            _createElementVNode(\"p\", null, \" Using our PACT (Prompt Attribution and Contribution Tracking) method, we measure how different parts of the input influence the model's decisions: \", -1),\n                            _createElementVNode(\"ul\", null, [\n                              _createElementVNode(\"li\", null, \"When correct answers are overturned, models show stronger attribution to refinement prompts\"),\n                              _createElementVNode(\"li\", null, \"When correct answers are retained, models maintain focus on the original question\")\n                            ], -1)\n                          ])),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_col, { span: 1 }),\n                        _createVNode(_component_el_col, { span: 11 }, {\n                          default: _withCtx(() => _cache[26] || (_cache[26] = [\n                            _createElementVNode(\"img\", {\n                              src: _imports_3,\n                              alt: \"Token Attribution Analysis\",\n                              class: \"method-image\"\n                            }, null, -1)\n                          ])),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }),\n                    _cache[27] || (_cache[27] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                      _createElementVNode(\"strong\", null, \"Observation 3:\"),\n                      _createTextVNode(\" Self-correction fails since LLMs are biased towards the refinement prompt rather than the original question. \")\n                    ], -1))\n                  ]),\n                  _createElementVNode(\"div\", _hoisted_12, [\n                    _createVNode(_component_el_row, { gutter: 20 }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_col, { span: 11 }, {\n                          default: _withCtx(() => _cache[28] || (_cache[28] = [\n                            _createElementVNode(\"h4\", null, \"3. Human-like Cognitive Bias Analysis\", -1),\n                            _createElementVNode(\"p\", null, \" In complex tasks, we identify three types of human-like cognitive biases that emerge during self-correction: \", -1),\n                            _createElementVNode(\"ul\", null, [\n                              _createElementVNode(\"li\", null, [\n                                _createElementVNode(\"strong\", null, \"Overthinking:\"),\n                                _createTextVNode(\" Excessive reasoning without taking correct actions (avg. 15.4 vs 5.3 \\\"think\\\" steps)\")\n                              ]),\n                              _createElementVNode(\"li\", null, [\n                                _createElementVNode(\"strong\", null, \"Cognitive Overload:\"),\n                                _createTextVNode(\" Forgetting critical information when processing long prompts\")\n                              ]),\n                              _createElementVNode(\"li\", null, [\n                                _createElementVNode(\"strong\", null, \"Perfectionism Bias:\"),\n                                _createTextVNode(\" Over-optimization leading to constraint violations\")\n                              ])\n                            ], -1)\n                          ])),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_col, { span: 13 }, {\n                          default: _withCtx(() => _cache[29] || (_cache[29] = [\n                            _createElementVNode(\"img\", {\n                              src: _imports_4,\n                              alt: \"Human Cognitive Biases\",\n                              class: \"method-image\"\n                            }, null, -1)\n                          ])),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }),\n                    _cache[30] || (_cache[30] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                      _createElementVNode(\"strong\", null, \"Observation 4:\"),\n                      _createTextVNode(\" In complex tasks, LLMs exhibit human-like cognitive biases during self-correction: (1) Overthinking: LLM performs excessive \\\"think\\\" without taking correct actions; (2) Cognitive overload: LLM forgets the correct command syntax when processing long prompt; (3) Perfectionism bias: LLM wants to be more efficient, but instead violates environmental restrictions. \")\n                    ], -1))\n                  ])\n                ])\n              ]),\n              _createElementVNode(\"div\", _hoisted_13, [\n                _cache[40] || (_cache[40] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Alleviation\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_14, [\n                  _cache[33] || (_cache[33] = _createElementVNode(\"p\", null, \" Based on our findings that self-correction failures are mainly due to model's behavior of changing answers when meeting refinement prompts, we propose two simple yet effective strategies: \", -1)),\n                  _cache[34] || (_cache[34] = _createElementVNode(\"div\", { style: {\"text-align\":\"center\"} }, [\n                    _createElementVNode(\"img\", {\n                      src: _imports_5,\n                      alt: \"Question Repeating\",\n                      class: \"responsive-image\",\n                      style: {\"width\":\"80%\"}\n                    })\n                  ], -1)),\n                  _cache[35] || (_cache[35] = _createElementVNode(\"div\", { class: \"solution-item\" }, [\n                    _createElementVNode(\"h4\", null, \"1. Question Repeating\"),\n                    _createElementVNode(\"p\", null, \" We attach the original question to the end of the refinement prompt to reduce recency bias. For example: \\\"Are you sure? Think and answer again.\\\" → \\\"Are you sure? Think and answer again. Is human a kind of animals?\\\" \")\n                  ], -1)),\n                  _cache[36] || (_cache[36] = _createElementVNode(\"div\", { class: \"solution-item\" }, [\n                    _createElementVNode(\"h4\", null, \"2. Low-cost Supervised Fine-Tuning (SFT)\"),\n                    _createElementVNode(\"p\", null, \" We fine-tune models with extremely few samples (4 for Llama, 10 for GPT) selected from correct→wrong cases, without introducing external knowledge. The cost is only $0.004 and 3 minutes. \")\n                  ], -1)),\n                  _cache[37] || (_cache[37] = _createElementVNode(\"h4\", null, \"Key Results\", -1)),\n                  _cache[38] || (_cache[38] = _createElementVNode(\"ul\", null, [\n                    _createElementVNode(\"li\", null, \"Both strategies significantly reduce self-correction failures in Yes/No questions\"),\n                    _createElementVNode(\"li\", null, \"SFT almost eliminates all correct→wrong cases\"),\n                    _createElementVNode(\"li\", null, \"Models fine-tuned on Yes/No questions can generalize to complex tasks\")\n                  ], -1)),\n                  _createVNode(_component_el_table, {\n                    data: mitigateData,\n                    style: {\"width\":\"100%\"},\n                    border: \"\"\n                  }, {\n                    default: _withCtx(() => [\n                      _createVNode(_component_el_table_column, {\n                        prop: \"model\",\n                        label: \"Model\",\n                        align: \"center\"\n                      }),\n                      _createVNode(_component_el_table_column, {\n                        prop: \"acc1\",\n                        label: \"ACC₁ (↓ΔACC) (%)\",\n                        align: \"center\"\n                      }),\n                      _createVNode(_component_el_table_column, {\n                        prop: \"overturned\",\n                        label: \"✓→✗ (%)\",\n                        align: \"center\"\n                      }, {\n                        default: _withCtx((scope) => [\n                          _createTextVNode(_toDisplayString(scope.row.overturned), 1)\n                        ]),\n                        _: 1\n                      })\n                    ]),\n                    _: 1\n                  }),\n                  _cache[39] || (_cache[39] = _createElementVNode(\"p\", { class: \"table-caption\" }, \"Table 2: Alleviating self-correction failure on Yes/No question answering task.\", -1))\n                ])\n              ]),\n              _cache[41] || (_cache[41] = _createElementVNode(\"div\", {\n                class: \"section\",\n                id: \"resources\"\n              }, [\n                _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Resources\")\n                ]),\n                _createElementVNode(\"div\", { class: \"section-content\" }, [\n                  _createElementVNode(\"p\", null, \" Access our code repository through the following links: \"),\n                  _createElementVNode(\"ul\", null, [\n                    _createElementVNode(\"li\", null, [\n                      _createElementVNode(\"a\", {\n                        href: \"https://anonymous.4open.science/r/SC-15FB/\",\n                        target: \"_blank\"\n                      }, \"Project Code\")\n                    ])\n                  ])\n                ])\n              ], -1))\n            ]),\n            _: 1\n          })\n        ]),\n        _: 1\n      })\n    ])\n  ]))\n}\n}\n\n})","<template>\n    <div class=\"project-page\">\n      <!-- Navigation Bar -->\n      <el-menu\n        mode=\"horizontal\"\n        :background-color=\"'rgb(140, 21, 21)'\"\n        text-color=\"#fff\"\n        active-text-color=\"#fff\"\n      >\n        <el-menu-item index=\"/\">\n          <span style=\"font-weight: 800\">X-ISC</span>\n        </el-menu-item>\n        <el-menu-item @click=\"scrollToSection('abstract')\">Abstract</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('failure')\">Failure of Intrinsic Self-Correction</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('interpretation')\">Interpretation</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('alleviation')\">Alleviation</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('resources')\">Resources</el-menu-item>\n      </el-menu>\n  \n      <!-- Header Section -->\n      <div class=\"container header\">\n        <h2 class=\"title\">Understanding the Dark Side of LLMs' Intrinsic Self-Correction</h2>\n        <h4 class=\"subtitle\">\n          <span class=\"underline\">Ex</span>plaining \n          <span class=\"underline\">I</span>ntrinsic \n          <span class=\"underline\">S</span>elf-<span class=\"underline\">C</span>orrection \n          (X-ISC)\n        </h4>\n        \n        <div class=\"author-info\">\n          <span>Anonymous submission</span>\n        </div>\n  \n        <!-- 添加 GitHub 链接按钮 -->\n        <div class=\"github-link-container\">\n          <a href=\"https://anonymous.4open.science/r/SC-15FB/\" \n             class=\"github-button\"\n             target=\"_blank\">\n            <i class=\"github-icon\">\n              <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"currentColor\" viewBox=\"0 0 16 16\">\n                <path d=\"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z\"/>\n              </svg>\n            </i>\n            <span>Project Code</span>\n          </a>\n        </div>\n      </div>\n  \n      <!-- Add New Image Row -->\n      <div class=\"container\">\n        <el-row justify=\"center\" class=\"gif-container\">\n          <el-col :xs=\"20\" :sm=\"16\" :md=\"8\" :lg=\"8\" class=\"gif-column\">\n            <img \n              src=\"@/figures/output.gif\" \n              alt=\"Output Animation 1\" \n              class=\"responsive-image gif-image\"\n            />\n          </el-col>\n          <el-col :xs=\"20\" :sm=\"16\" :md=\"8\" :lg=\"8\" class=\"gif-column\">\n            <img \n              src=\"@/figures/output.gif\" \n              alt=\"Output Animation 2\" \n              class=\"responsive-image gif-image\"\n            />\n          </el-col>\n        </el-row>\n      </div>\n  \n      <!-- Main Content -->\n      <div class=\"container main-content\">\n        <el-row justify=\"center\">\n          <el-col :span=\"20\">\n            <!-- Abstract Section -->\n            <div class=\"section\" id=\"abstract\">\n              <h3>\n                <span class=\"section-title\">Abstract</span>\n              </h3>\n              <div class=\"section-content\">\n                <el-row :gutter=\"20\">\n                    <el-col :span=\"1\"></el-col>\n                  <el-col :span=\"11\">\n                    <p>\n                      Intrinsic self-correction was proposed to improve LLMs' responses via feedback solely based on their inherent capability. However, recent works show that LLMs' intrinsic self-correction fails without oracle labels as feedback. In this paper, we aim to interpret LLMs' intrinsic self-correction for different tasks, especially for those failure cases? By including one simple task and three complex tasks with state-of-the-art (SOTA) LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B, and 3.1-8B), we design interpretation methods to reveal the dark side of SOTA LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1) cause LLMs to waver both intermedia and final answers and lead to prompt bias on simple factual questions; (2) introduce human-like cognitive bias on complex tasks. In light of our findings, we also provide two simple, low-cost, yet effective strategies for alleviation: question repeating and supervised fine-tuning.\n                    </p>\n                  </el-col>\n                <el-col :span=\"10\">\n                    <img \n                        src=\"@/figures/overviewf3.png\" \n                        alt=\"Overview\" \n                        class=\"responsive-image abstract-image\"\n                    />\n                    </el-col>\n                </el-row>\n              </div>\n            </div>\n  \n            <!-- Failure of Intrinsic Self-Correction Section -->\n            <div class=\"section\" id=\"failure\">\n              <h3>\n                <span class=\"section-title\">Failure of Intrinsic Self-Correction</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  Intrinsic self-correction mechanisms in state-of-the-art LLMs were expected to enhance performance by refining responses based solely on the model's inherent capabilities. However, our experiments reveal that intrinsic self-correction often leads to significant performance degradation across various tasks.\n                </p>\n  \n                <!-- Experimental Tables Placeholder -->\n                <h4>Experimental Results</h4>\n                <p>Below are the key experimental results demonstrating the failures of intrinsic self-correction:</p>\n                \n                <!-- Example Table for Yes/No Question Answering Task -->\n                <el-table :data=\"boolqData\" style=\"width: 100%\" border>\n                  <el-table-column prop=\"model\" label=\"Model\" align=\"center\">\n                  </el-table-column>\n                  <el-table-column prop=\"acc1\" label=\"ACC₁ (↓ΔACC) (%)\" align=\"center\">\n                  </el-table-column>\n                  <el-table-column prop=\"overturned\" label=\"✓→✗ (%)\" align=\"center\">\n                    <template #default=\"scope\">\n                      {{ scope.row.overturned }}\n                    </template>\n                  </el-table-column>\n                </el-table>\n                \n                <p class=\"table-caption\">Table 1: Self-correction performance on the Yes/No question answering task.</p>\n  \n                <!-- Additional Tables for Complex Tasks -->\n                <!-- Repeat similar <el-table> components for other tasks as needed -->\n                \n                <!-- Observation 1 -->\n                <div class=\"observation-box\">\n                  <strong>Observation 1:</strong> Self-correction can fail in diverse tasks. For SOTA LLMs, self-correction failures are reduced but not solved. They are even worse in certain tasks.\n                </div>\n              </div>\n            </div>\n  \n            <!-- Interpretation Section -->\n            <div class=\"section\" id=\"interpretation\">\n              <h3>\n                <span class=\"section-title\">Interpretation</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  We propose three interpretation methods to understand how and why intrinsic self-correction fails in different tasks:\n                </p>\n  \n                <!-- Method 1: Mechanistic Interpretability -->\n                <div class=\"method-box\">\n                  <el-row :gutter=\"20\">\n                    <el-col :span=\"12\">\n                      <h4>1. Internal Answer Wavering</h4>\n                      <p>\n                        We analyze LLMs' internal token representations at each layer to track how confidence in different answers evolves. Our findings show that:\n                      </p>\n                      <ul>\n                        <li>Self-correction increases internal answer wavering from 8.3% to 14.1%</li>\n                        <li>Prompting with \"Are you sure?\" produces nearly identical confidence patterns as directly stating \"You are wrong\"</li>\n                      </ul>\n                    </el-col>\n                    <el-col :span=\"12\">\n                      <img \n                        src=\"@/figures/internal_confidence.png\" \n                        alt=\"Internal Confidence Analysis\" \n                        class=\"method-image\"\n                      />\n                    </el-col>\n                  </el-row>\n                  <div class=\"observation-box\">\n                    <strong>Observation 2:</strong> Self-correction causes internal answer wavering, which could further lead to wrong final answers. Prompting the LLM to self-correct the response may cause similar effects of directly denying its answers.\n                  </div>\n                </div>\n  \n                <!-- Method 2: Token Attribution -->\n                <div class=\"method-box\">\n                  <el-row :gutter=\"20\">\n                    <el-col :span=\"11\">\n                      <h4>2. Token Attribution Analysis: Prompt Bias</h4>\n                      <p>\n                        Using our PACT (Prompt Attribution and Contribution Tracking) method, we measure how different parts of the input influence the model's decisions:\n                      </p>\n                      <ul>\n                        <li>When correct answers are overturned, models show stronger attribution to refinement prompts</li>\n                        <li>When correct answers are retained, models maintain focus on the original question</li>\n                      </ul>\n                    </el-col>\n                    <el-col :span=\"1\"></el-col>\n                    <el-col :span=\"11\">\n                      <img \n                        src=\"@/figures/case.png\" \n                        alt=\"Token Attribution Analysis\" \n                        class=\"method-image\"\n                      />\n                    </el-col>\n                  </el-row>\n                  <div class=\"observation-box\">\n                    <strong>Observation 3:</strong> Self-correction fails since LLMs are biased towards the refinement prompt rather than the original question. \n                  </div>\n                </div>\n  \n                <!-- Method 3: Human-like Cognitive Bias -->\n                <div class=\"method-box\">\n                  <el-row :gutter=\"20\">\n                    <el-col :span=\"11\">\n                      <h4>3. Human-like Cognitive Bias Analysis</h4>\n                      <p>\n                        In complex tasks, we identify three types of human-like cognitive biases that emerge during self-correction:\n                      </p>\n                      <ul>\n                        <li><strong>Overthinking:</strong> Excessive reasoning without taking correct actions (avg. 15.4 vs 5.3 \"think\" steps)</li>\n                        <li><strong>Cognitive Overload:</strong> Forgetting critical information when processing long prompts</li>\n                        <li><strong>Perfectionism Bias:</strong> Over-optimization leading to constraint violations</li>\n                      </ul>\n                    </el-col>\n                    <el-col :span=\"13\">\n                      <img \n                        src=\"@/figures/humanCognitiveBiasf.png\" \n                        alt=\"Human Cognitive Biases\" \n                        class=\"method-image\"\n                      />\n                    </el-col>\n                  </el-row>\n                  <div class=\"observation-box\">\n                    <strong>Observation 4:</strong> In complex tasks, LLMs exhibit human-like cognitive biases during self-correction: (1) Overthinking: LLM performs excessive \"think\" without taking correct actions; (2) Cognitive overload: LLM forgets the correct command syntax when processing long prompt; (3) Perfectionism bias: LLM wants to be more efficient, but instead violates environmental restrictions.\n                  </div>\n                </div>\n              </div>\n            </div>\n  \n            <!-- Solutions Section -->\n            <div class=\"section\" id=\"alleviation\">\n              <h3>\n                <span class=\"section-title\">Alleviation</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  Based on our findings that self-correction failures are mainly due to model's behavior of changing answers when meeting refinement prompts, we propose two simple yet effective strategies:\n                </p>\n                <div style=\"text-align: center;\">\n                  <img src=\"@/figures/mergedMitigation2.png\" alt=\"Question Repeating\" class=\"responsive-image\" style=\"width: 80%;\" />\n                </div>\n  \n                <!-- Mitigation Strategy 1: Question Repeating -->\n                <div class=\"solution-item\">\n                  <h4>1. Question Repeating</h4>\n                  <p>\n                    We attach the original question to the end of the refinement prompt to reduce recency bias. For example:\n                    \"Are you sure? Think and answer again.\" → \"Are you sure? Think and answer again. Is human a kind of animals?\"\n                  </p>\n                </div>\n  \n                <!-- Mitigation Strategy 2: Supervised Fine-Tuning -->\n                <div class=\"solution-item\">\n                  <h4>2. Low-cost Supervised Fine-Tuning (SFT)</h4>\n                  <p>\n                    We fine-tune models with extremely few samples (4 for Llama, 10 for GPT) selected from correct→wrong cases, without introducing external knowledge. The cost is only $0.004 and 3 minutes.\n                  </p>\n                </div>\n  \n                <!-- Results -->\n                <h4>Key Results</h4>\n                <ul>\n                  <li>Both strategies significantly reduce self-correction failures in Yes/No questions</li>\n                  <li>SFT almost eliminates all correct→wrong cases</li>\n                  <li>Models fine-tuned on Yes/No questions can generalize to complex tasks</li>\n                </ul>\n  \n                <!-- Results Tables -->\n                <el-table :data=\"mitigateData\" style=\"width: 100%\" border>\n                  <el-table-column prop=\"model\" label=\"Model\" align=\"center\">\n                  </el-table-column>\n                  <el-table-column prop=\"acc1\" label=\"ACC₁ (↓ΔACC) (%)\" align=\"center\">\n                  </el-table-column>\n                  <el-table-column prop=\"overturned\" label=\"✓→✗ (%)\" align=\"center\">\n                    <template #default=\"scope\">\n                      {{ scope.row.overturned }}\n                    </template>\n                  </el-table-column>\n                </el-table>\n                <p class=\"table-caption\">Table 2: Alleviating self-correction failure on Yes/No question answering task.</p>\n              </div>\n            </div>\n  \n            <!-- Resources Section -->\n            <div class=\"section\" id=\"resources\">\n              <h3>\n                <span class=\"section-title\">Resources</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  Access our code repository through the following links:\n                </p>\n                <ul>\n                  <li><a href=\"https://anonymous.4open.science/r/SC-15FB/\" target=\"_blank\">Project Code</a></li>\n                </ul>\n              </div>\n            </div>\n          </el-col>\n        </el-row>\n      </div>\n    </div>\n  </template>\n  \n  <script setup lang=\"ts\">\n  // No additional scripts needed for static content\n  \n  // Sample Data for Tables\n  const boolqData = [\n    { \n      model: 'ChatGPT o1-preview', \n      acc1: '78.7 (↓4.9)', \n      overturned: '13.2' \n    },\n    { \n      model: 'ChatGPT o1-mini', \n      acc1: '74.1 (↓4.2)', \n      overturned: '15.6' \n    },\n    { \n      model: 'ChatGPT 4o', \n      acc1: '79.2 (↓4.9)', \n      overturned: '11.3' \n    },\n    { \n      model: 'ChatGPT 3.5-turbo', \n      acc1: '62.5 (↓12.1)', \n      overturned: '34.0' \n    },\n    { \n      model: 'Llama-3.1-8B', \n      acc1: '49.2 (↓20.4)', \n      overturned: '58.8' \n    },\n    { \n      model: 'Llama-3-8B', \n      acc1: '50.1 (↓20.3)', \n      overturned: '58.2' \n    },\n    { \n      model: 'Llama-2-7B', \n      acc1: '52.8 (↓8.7)', \n      overturned: '26.5' \n    }\n  ];\n  \n  const mitigateData = [\n    { model: 'GPT-4o', acc1: '79.2 (↓4.9)', overturned: '11.3' },\n    { model: 'GPT-4o + Question repeating', acc1: '83.6 (↓0.5)', overturned: '6.0' },\n    { model: 'GPT-4o + SFT', acc1: '87.7 (↑4.1)', overturned: '0' },\n    { model: 'GPT-3.5-turbo', acc1: '62.5 (↓12.1)', overturned: '34.0' },\n    { model: 'GPT-3.5-turbo + Question repeating', acc1: '67.4 (↓7.2)', overturned: '23.1' },\n    { model: 'GPT-3.5-turbo + SFT', acc1: '76.2 (↑1.6)', overturned: '0' },\n    { model: 'Llama-3.1-8B', acc1: '49.2 (↓20.4)', overturned: '58.8' },\n    { model: 'Llama-3.1-8B + Question repeating', acc1: '52.4 (↓17.2)', overturned: '52.8' },\n    { model: 'Llama-3.1-8B + SFT', acc1: '70.3 (↑0.7)', overturned: '0' }\n  ];\n  \n  const scrollToSection = (sectionId: string) => {\n    const element = document.getElementById(sectionId);\n    if (element) {\n      element.scrollIntoView({ behavior: 'smooth' });\n    }\n  };\n  </script>\n  \n  <style scoped>\n  .project-page {\n    min-height: 100vh;\n    background-color: #fff;\n  }\n  \n  .container {\n    padding: 0 20px;\n    max-width: 1200px;\n    margin: 0 auto;\n  }\n  \n  .header {\n    text-align: center;\n    padding: 20px 0 0 0;\n  }\n  \n  .title {\n    margin-bottom: 0;\n    font-size: 2em;\n    font-weight: normal;\n  }\n  \n  .subtitle {\n    color: rgb(140, 21, 21);\n    margin-top: 5px;\n    margin-bottom: 5px;\n    font-weight: normal;\n    font-size: 1.5em;\n  }\n  \n  .section {\n    margin: 15px 0;\n    padding: 0px;\n    background-color: transparent;\n    border-radius: 0;\n    box-shadow: none;\n  }\n  \n  .section-title {\n    color: rgb(140, 21, 21);\n    font-size: 22px;\n    display: block;\n    margin-bottom: 10px;\n    border-bottom: 2px solid rgb(140, 21, 21);\n    padding-bottom: 6px;\n  }\n  \n  .section-content {\n    margin-top: 15px;\n  }\n  \n  .observation-box {\n    margin: 15px 0;\n    padding: 12px;\n    background-color: #f0f8ff;\n    border-left: 4px solid rgb(140, 21, 21);\n    border-radius: 4px;\n  }\n  \n  .table-caption {\n    text-align: center;\n    font-size: 0.85em;\n    color: #555;\n    margin: 5px auto 15px;\n    width: 80%;\n  }\n  \n  .solution-item {\n    margin-bottom: 15px;\n    padding: 15px;\n    background-color: #f8f8f8;\n    border-radius: 8px;\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n  }\n  \n  .solution-item h4 {\n    color: rgb(140, 21, 21);\n    margin-top: 0;\n    margin-bottom: 10px;\n  }\n  \n  .responsive-image {\n    width: 100%;\n    height: auto;\n    margin-top: 15px;\n    border-radius: 8px;\n  }\n  \n  /* 移除之前的 overview 图片特殊样式 */\n  #abstract .responsive-image {\n    max-width: 100%;\n    margin: 0;\n  }\n  \n  /* 添加新的 abstract 图片样式 */\n  .abstract-image {\n    width: 100%;\n    height: auto;\n    display: block;\n    margin: 15px 0;\n  }\n  \n  /* 为双栏布局加响应式设计 */\n  @media (max-width: 768px) {\n    .finding-item, .method-item, .result-item, .solution-item {\n      padding: 15px;\n    }\n  \n    .section-title {\n      font-size: 22px;\n    }\n  \n    .title {\n      font-size: 1.8em;\n    }\n  \n    .subtitle {\n      font-size: 1.3em;\n    }\n  \n    #abstract .el-row {\n      display: flex;\n      flex-direction: column;\n    }\n  \n    #abstract .el-col {\n      width: 100%;\n      margin-bottom: 20px;\n    }\n  }\n  \n  .github-link-container {\n    text-align: center;\n    margin: 10px 0 0 0;\n  }\n  \n  .github-button {\n    display: inline-flex;\n    align-items: center;\n    gap: 8px;\n    background-color: rgb(140, 21, 21);\n    color: white;\n    padding: 8px 15px;\n    border-radius: 20px;\n    text-decoration: none;\n    font-size: 14px;\n    transition: background-color 0.3s;\n  }\n  \n  .github-button:hover {\n    background-color: rgb(120, 18, 18);\n    color: white;\n    text-decoration: none;\n  }\n  \n  .github-icon {\n    display: flex;\n    align-items: center;\n  }\n  \n  :deep(.el-menu-item) {\n    font-size: 18px;  /* 增加字体大小 */\n    font-weight: 400; /* 稍微加粗一点 */\n  }\n  \n  :deep(.el-menu-item:first-child) {\n    font-size: 20px;\n    font-weight: 800;\n  }\n  \n  /* 修改表格样式 */\n  :deep(.el-table) {\n    margin: 20px auto;\n    width: 80% !important;\n    font-size: 14px;\n  }\n  \n  :deep(.el-table__header) {\n    font-weight: bold;\n    font-size: 14px;\n  }\n  \n  :deep(.el-table__cell) {\n    text-align: center !important;\n    padding: 6px 0;\n  }\n  \n  :deep(.el-table .cell) {\n    padding: 4px;\n    white-space: nowrap;\n  }\n  \n  /* 调整标题和段落的间距 */\n  h4 {\n    margin-top: 15px;\n    margin-bottom: 10px;\n    font-size: 18px; /* 减小二级标题大小 */\n  }\n  \n  p {\n    margin: 8px 0; /* 减小段落间距 */\n    line-height: 1.5; /* 减小行 */\n  }\n  \n  /* 添加新的样式类用于中等大小的图片 */\n  .medium-image {\n    width: 70%;  /* 设置为容器宽度的70% */\n    display: block;\n    margin: 15px auto;  /* 上下间距15px，左右自动居中 */\n  }\n  \n  .method-box {\n    margin: 25px 0;\n    padding: 20px;\n    background-color: #f8f8f8;\n    border-radius: 8px;\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n  }\n  \n  .method-box h4 {\n    color: rgb(140, 21, 21);\n    margin-top: 0;\n    margin-bottom: 15px;\n  }\n  \n  .method-image {\n    width: 100%;\n    height: auto;\n    border-radius: 8px;\n    margin-top: 10px;\n  }\n  \n  /* 添加以下样式来调整列表项的左边距 */\n  ul {\n    padding-left: 20px; /* 减默认的左边距 */\n    margin: 8px 0;\n  }\n  \n  li {\n    margin: 4px 0; /* 调整列表项之间的垂直间距 */\n  }\n  \n  /* 添加新的样式规则 */\n  #abstract {\n    margin-top: 0;\n    padding-top: 0;\n  }\n  \n  .underline {\n    text-decoration: underline;\n  }\n  \n  .gif-container {\n    margin: 15px auto 30px;\n    text-align: center;\n    display: flex;\n    justify-content: center;\n    gap: 30px;\n  }\n  \n  .gif-column {\n    display: flex;\n    justify-content: center;\n  }\n  \n  .gif-image {\n    width: 100%;\n    max-width: 450px;\n    height: auto;\n    border-radius: 8px;\n    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n  }\n  </style>\n  ","import script from \"./ProjectView.vue?vue&type=script&setup=true&lang=ts\"\nexport * from \"./ProjectView.vue?vue&type=script&setup=true&lang=ts\"\n\nimport \"./ProjectView.vue?vue&type=style&index=0&id=2b1ff5f8&scoped=true&lang=css\"\n\nimport exportComponent from \"../../node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['__scopeId',\"data-v-2b1ff5f8\"]])\n\nexport default __exports__"],"names":["_hoisted_1","class","_hoisted_2","_hoisted_3","_hoisted_4","id","_hoisted_5","_hoisted_6","_hoisted_7","_hoisted_8","_hoisted_9","_hoisted_10","_hoisted_11","_hoisted_12","_hoisted_13","_hoisted_14","_defineComponent","__name","setup","__props","boolqData","model","acc1","overturned","mitigateData","scrollToSection","sectionId","element","document","getElementById","scrollIntoView","behavior","_ctx","_cache","_component_el_menu_item","_resolveComponent","_component_el_menu","_component_el_col","_component_el_row","_component_el_table_column","_component_el_table","_openBlock","_createElementBlock","_createVNode","mode","default","_withCtx","index","_createElementVNode","style","_","onClick","$event","_createTextVNode","_createStaticVNode","justify","xs","sm","md","lg","src","_imports_0","alt","span","gutter","_imports_1","data","border","prop","label","align","scope","_toDisplayString","row","_imports_2","_imports_3","_imports_4","_imports_5","href","target","__exports__"],"sourceRoot":""}