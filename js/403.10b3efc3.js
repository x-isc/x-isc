"use strict";(self["webpackChunkX_ISC"]=self["webpackChunkX_ISC"]||[]).push([[403],{98095:(e,n,t)=>{t.r(n),t.d(n,{default:()=>G});t(50113),t(26099),t(47764),t(98992),t(72577),t(62953),t(3296),t(27208),t(48408),t(14603),t(47566),t(98721);var i=t(56768),o=t(24232);const a=t.p+"img/overviewf3.72aca71c.png",r=t.p+"img/internal_confidence.60b88c7c.png",s=t.p+"img/case.86d0efe0.png",l=t.p+"img/humanCognitiveBiasf.e0097809.png",c=t.p+"img/mergedMitigation2.1e7564fc.png";var u=t(90144),d={class:"project-page"},f={class:"video-section"},p={class:"video-options"},v={class:"video-selector-list"},k=["onClick"],m={class:"model-name"},h={class:"question"},g={class:"video-player"},L=["src"],b={class:"container main-content"},w={class:"section",id:"abstract"},C={class:"section-content"},y={class:"section",id:"failure"},F={class:"section-content"},_={class:"section",id:"interpretation"},T={class:"section-content"},x={class:"method-box"},P={class:"method-box"},A={class:"method-box"},I={class:"section",id:"alleviation"},S={class:"section-content"};const M=(0,i.pM)({__name:"ProjectView",setup:function(e){var n=[{model:"ChatGPT o1-preview",acc1:"78.7 (↓4.9)",overturned:"13.2"},{model:"ChatGPT o1-mini",acc1:"74.1 (↓4.2)",overturned:"15.6"},{model:"ChatGPT 4o",acc1:"79.2 (↓4.9)",overturned:"11.3"},{model:"ChatGPT 3.5-turbo",acc1:"62.5 (↓12.1)",overturned:"34.0"},{model:"Llama-3.1-8B",acc1:"49.2 (↓20.4)",overturned:"58.8"},{model:"Llama-3-8B",acc1:"50.1 (↓20.3)",overturned:"58.2"},{model:"Llama-2-7B",acc1:"52.8 (↓8.7)",overturned:"26.5"}],M=[{model:"GPT-4o",acc1:"79.2 (↓4.9)",overturned:"11.3"},{model:"GPT-4o + Question repeating",acc1:"83.6 (↓0.5)",overturned:"6.0"},{model:"GPT-4o + SFT",acc1:"87.7 (↑4.1)",overturned:"0"},{model:"GPT-3.5-turbo",acc1:"62.5 (↓12.1)",overturned:"34.0"},{model:"GPT-3.5-turbo + Question repeating",acc1:"67.4 (↓7.2)",overturned:"23.1"},{model:"GPT-3.5-turbo + SFT",acc1:"76.2 (↑1.6)",overturned:"0"},{model:"Llama-3.1-8B",acc1:"49.2 (↓20.4)",overturned:"58.8"},{model:"Llama-3.1-8B + Question repeating",acc1:"52.4 (↓17.2)",overturned:"52.8"},{model:"Llama-3.1-8B + SFT",acc1:"70.3 (↑0.7)",overturned:"0"}],W=function(e){var n=document.getElementById(e);n&&n.scrollIntoView({behavior:"smooth"})},B=new URL(t(19769),t.b).href,G=new URL(t(66251),t.b).href,q=new URL(t(28522),t.b).href,O=new URL(t(71482),t.b).href,Q=[{value:"4o",label:"GPT-4o - Population Question",model:"ChatGPT 4o (2024.12.17)",question:"Does China has more population than India?",src:B},{value:"4o-mini",label:"GPT-4o - Moon Jump Question",model:"ChatGPT 4o mini (2024.12.17)",question:"Can I jump from Earth to Moon?",src:G},{value:"o1",label:"GPT-o1 - Population Question",model:"ChatGPT o1 (2024.12.17)",question:"Does China has more population than India?",src:q},{value:"o1-mini",label:"GPT-o1 - Arms Question",model:"ChatGPT o1-mini (2024.12.17)",question:"Does human have three arms?",src:O}],R=(0,u.KR)("4o"),E=(0,i.EW)((function(){var e=Q.find((function(e){return e.value===R.value}));return e?e.src:""}));return function(e,t){var u=(0,i.g2)("el-menu-item"),B=(0,i.g2)("el-menu"),G=(0,i.g2)("el-col"),q=(0,i.g2)("el-row"),O=(0,i.g2)("el-table-column"),X=(0,i.g2)("el-table");return(0,i.uX)(),(0,i.CE)("div",d,[(0,i.bF)(B,{mode:"horizontal","background-color":"rgb(140, 21, 21)","text-color":"#fff","active-text-color":"#fff"},{default:(0,i.k6)((function(){return[(0,i.bF)(u,{index:"/"},{default:(0,i.k6)((function(){return t[5]||(t[5]=[(0,i.Lk)("span",{style:{"font-weight":"800"}},"X-ISC",-1)])})),_:1}),(0,i.bF)(u,{onClick:t[0]||(t[0]=function(e){return W("abstract")})},{default:(0,i.k6)((function(){return t[6]||(t[6]=[(0,i.eW)("Abstract")])})),_:1}),(0,i.bF)(u,{onClick:t[1]||(t[1]=function(e){return W("failure")})},{default:(0,i.k6)((function(){return t[7]||(t[7]=[(0,i.eW)("Failure of Intrinsic Self-Correction")])})),_:1}),(0,i.bF)(u,{onClick:t[2]||(t[2]=function(e){return W("interpretation")})},{default:(0,i.k6)((function(){return t[8]||(t[8]=[(0,i.eW)("Interpretation")])})),_:1}),(0,i.bF)(u,{onClick:t[3]||(t[3]=function(e){return W("alleviation")})},{default:(0,i.k6)((function(){return t[9]||(t[9]=[(0,i.eW)("Alleviation")])})),_:1}),(0,i.bF)(u,{onClick:t[4]||(t[4]=function(e){return W("resources")})},{default:(0,i.k6)((function(){return t[10]||(t[10]=[(0,i.eW)("Resources")])})),_:1})]})),_:1}),t[41]||(t[41]=(0,i.Fv)('<div class="container header" data-v-3a126768><h2 class="title" data-v-3a126768>Understanding the Dark Side of LLMs&#39; Intrinsic Self-Correction</h2><h4 class="subtitle" data-v-3a126768><span class="underline" data-v-3a126768>Ex</span>plaining <span class="underline" data-v-3a126768>I</span>ntrinsic <span class="underline" data-v-3a126768>S</span>elf-<span class="underline" data-v-3a126768>C</span>orrection (X-ISC) </h4><div class="author-info" data-v-3a126768><span data-v-3a126768>Anonymous submission</span></div><div class="github-link-container" data-v-3a126768><a href="https://anonymous.4open.science/r/SC-15FB/" class="github-button" target="_blank" data-v-3a126768><i class="github-icon" data-v-3a126768><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16" data-v-3a126768><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-v-3a126768></path></svg></i><span data-v-3a126768>Project Code</span></a></div></div>',1)),(0,i.Lk)("div",f,[(0,i.bF)(q,{gutter:10},{default:(0,i.k6)((function(){return[(0,i.bF)(G,{span:7},{default:(0,i.k6)((function(){return[(0,i.Lk)("div",p,[(0,i.Lk)("div",v,[t[11]||(t[11]=(0,i.Lk)("div",{class:"video-option-header"}," Select Model & Question: ",-1)),((0,i.uX)(),(0,i.CE)(i.FK,null,(0,i.pI)(Q,(function(e){return(0,i.Lk)("div",{key:e.value,class:(0,o.C4)(["video-option-item",{active:R.value===e.value}]),onClick:function(n){return R.value=e.value}},[(0,i.Lk)("div",m,(0,o.v_)(e.model),1),(0,i.Lk)("div",h,(0,o.v_)(e.question),1)],10,k)})),64))])])]})),_:1}),(0,i.bF)(G,{span:15},{default:(0,i.k6)((function(){return[(0,i.Lk)("div",g,[E.value?((0,i.uX)(),(0,i.CE)("video",{key:0,src:E.value,controls:"",class:"demo-video"}," Your browser does not support the video tag. ",8,L)):(0,i.Q3)("",!0)])]})),_:1})]})),_:1})]),(0,i.Lk)("div",b,[(0,i.bF)(q,{justify:"center"},{default:(0,i.k6)((function(){return[(0,i.bF)(G,{span:20},{default:(0,i.k6)((function(){return[(0,i.Lk)("div",w,[t[14]||(t[14]=(0,i.Lk)("h3",null,[(0,i.Lk)("span",{class:"section-title"},"Abstract")],-1)),(0,i.Lk)("div",C,[(0,i.bF)(q,{gutter:20},{default:(0,i.k6)((function(){return[(0,i.bF)(G,{span:1}),(0,i.bF)(G,{span:11},{default:(0,i.k6)((function(){return t[12]||(t[12]=[(0,i.Lk)("p",null," Intrinsic self-correction was proposed to improve LLMs' responses via feedback solely based on their inherent capability. However, recent works show that LLMs' intrinsic self-correction fails without oracle labels as feedback. In this paper, we aim to interpret LLMs' intrinsic self-correction for different tasks, especially for those failure cases? By including one simple task and three complex tasks with state-of-the-art (SOTA) LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B, and 3.1-8B), we design interpretation methods to reveal the dark side of SOTA LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1) cause LLMs to waver both intermedia and final answers and lead to prompt bias on simple factual questions; (2) introduce human-like cognitive bias on complex tasks. In light of our findings, we also provide two simple, low-cost, yet effective strategies for alleviation: question repeating and supervised fine-tuning. ",-1)])})),_:1}),(0,i.bF)(G,{span:10},{default:(0,i.k6)((function(){return t[13]||(t[13]=[(0,i.Lk)("img",{src:a,alt:"Overview",class:"responsive-image abstract-image"},null,-1)])})),_:1})]})),_:1})])]),(0,i.Lk)("div",y,[t[20]||(t[20]=(0,i.Lk)("h3",null,[(0,i.Lk)("span",{class:"section-title"},"Failure of Intrinsic Self-Correction")],-1)),(0,i.Lk)("div",F,[t[15]||(t[15]=(0,i.Lk)("p",null," Intrinsic self-correction mechanisms in state-of-the-art LLMs were expected to enhance performance by refining responses based solely on the model's inherent capabilities. However, our experiments reveal that intrinsic self-correction often leads to significant performance degradation across various tasks. ",-1)),t[16]||(t[16]=(0,i.Lk)("h4",null,"Experimental Results",-1)),t[17]||(t[17]=(0,i.Lk)("p",null,"Below are the key experimental results demonstrating the failures of intrinsic self-correction:",-1)),(0,i.bF)(X,{data:n,style:{width:"100%"},border:""},{default:(0,i.k6)((function(){return[(0,i.bF)(O,{prop:"model",label:"Model",align:"center"}),(0,i.bF)(O,{prop:"acc1",label:"ACC₁ (↓ΔACC) (%)",align:"center"}),(0,i.bF)(O,{prop:"overturned",label:"✓→✗ (%)",align:"center"},{default:(0,i.k6)((function(e){return[(0,i.eW)((0,o.v_)(e.row.overturned),1)]})),_:1})]})),_:1}),t[18]||(t[18]=(0,i.Lk)("p",{class:"table-caption"},"Table 1: Self-correction performance on the Yes/No question answering task.",-1)),t[19]||(t[19]=(0,i.Lk)("div",{class:"observation-box"},[(0,i.Lk)("strong",null,"Observation 1:"),(0,i.eW)(" Self-correction can fail in diverse tasks. For SOTA LLMs, self-correction failures are reduced but not solved. They are even worse in certain tasks. ")],-1))])]),(0,i.Lk)("div",_,[t[31]||(t[31]=(0,i.Lk)("h3",null,[(0,i.Lk)("span",{class:"section-title"},"Interpretation")],-1)),(0,i.Lk)("div",T,[t[30]||(t[30]=(0,i.Lk)("p",null," We propose three interpretation methods to understand how and why intrinsic self-correction fails in different tasks: ",-1)),(0,i.Lk)("div",x,[(0,i.bF)(q,{gutter:20},{default:(0,i.k6)((function(){return[(0,i.bF)(G,{span:12},{default:(0,i.k6)((function(){return t[21]||(t[21]=[(0,i.Lk)("h4",null,"1. Internal Answer Wavering",-1),(0,i.Lk)("p",null," We analyze LLMs' internal token representations at each layer to track how confidence in different answers evolves. Our findings show that: ",-1),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Self-correction increases internal answer wavering from 8.3% to 14.1%"),(0,i.Lk)("li",null,'Prompting with "Are you sure?" produces nearly identical confidence patterns as directly stating "You are wrong"')],-1)])})),_:1}),(0,i.bF)(G,{span:12},{default:(0,i.k6)((function(){return t[22]||(t[22]=[(0,i.Lk)("img",{src:r,alt:"Internal Confidence Analysis",class:"method-image"},null,-1)])})),_:1})]})),_:1}),t[23]||(t[23]=(0,i.Lk)("div",{class:"observation-box"},[(0,i.Lk)("strong",null,"Observation 2:"),(0,i.eW)(" Self-correction causes internal answer wavering, which could further lead to wrong final answers. Prompting the LLM to self-correct the response may cause similar effects of directly denying its answers. ")],-1))]),(0,i.Lk)("div",P,[(0,i.bF)(q,{gutter:20},{default:(0,i.k6)((function(){return[(0,i.bF)(G,{span:11},{default:(0,i.k6)((function(){return t[24]||(t[24]=[(0,i.Lk)("h4",null,"2. Token Attribution Analysis: Prompt Bias",-1),(0,i.Lk)("p",null," Using our PACT (Prompt Attribution and Contribution Tracking) method, we measure how different parts of the input influence the model's decisions: ",-1),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"When correct answers are overturned, models show stronger attribution to refinement prompts"),(0,i.Lk)("li",null,"When correct answers are retained, models maintain focus on the original question")],-1)])})),_:1}),(0,i.bF)(G,{span:1}),(0,i.bF)(G,{span:11},{default:(0,i.k6)((function(){return t[25]||(t[25]=[(0,i.Lk)("img",{src:s,alt:"Token Attribution Analysis",class:"method-image"},null,-1)])})),_:1})]})),_:1}),t[26]||(t[26]=(0,i.Lk)("div",{class:"observation-box"},[(0,i.Lk)("strong",null,"Observation 3:"),(0,i.eW)(" Self-correction fails since LLMs are biased towards the refinement prompt rather than the original question. ")],-1))]),(0,i.Lk)("div",A,[(0,i.bF)(q,{gutter:20},{default:(0,i.k6)((function(){return[(0,i.bF)(G,{span:11},{default:(0,i.k6)((function(){return t[27]||(t[27]=[(0,i.Lk)("h4",null,"3. Human-like Cognitive Bias Analysis",-1),(0,i.Lk)("p",null," In complex tasks, we identify three types of human-like cognitive biases that emerge during self-correction: ",-1),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Overthinking:"),(0,i.eW)(' Excessive reasoning without taking correct actions (avg. 15.4 vs 5.3 "think" steps)')]),(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Cognitive Overload:"),(0,i.eW)(" Forgetting critical information when processing long prompts")]),(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Perfectionism Bias:"),(0,i.eW)(" Over-optimization leading to constraint violations")])],-1)])})),_:1}),(0,i.bF)(G,{span:13},{default:(0,i.k6)((function(){return t[28]||(t[28]=[(0,i.Lk)("img",{src:l,alt:"Human Cognitive Biases",class:"method-image"},null,-1)])})),_:1})]})),_:1}),t[29]||(t[29]=(0,i.Lk)("div",{class:"observation-box"},[(0,i.Lk)("strong",null,"Observation 4:"),(0,i.eW)(' In complex tasks, LLMs exhibit human-like cognitive biases during self-correction: (1) Overthinking: LLM performs excessive "think" without taking correct actions; (2) Cognitive overload: LLM forgets the correct command syntax when processing long prompt; (3) Perfectionism bias: LLM wants to be more efficient, but instead violates environmental restrictions. ')],-1))])])]),(0,i.Lk)("div",I,[t[39]||(t[39]=(0,i.Lk)("h3",null,[(0,i.Lk)("span",{class:"section-title"},"Alleviation")],-1)),(0,i.Lk)("div",S,[t[32]||(t[32]=(0,i.Lk)("p",null," Based on our findings that self-correction failures are mainly due to model's behavior of changing answers when meeting refinement prompts, we propose two simple yet effective strategies: ",-1)),t[33]||(t[33]=(0,i.Lk)("div",{style:{"text-align":"center"}},[(0,i.Lk)("img",{src:c,alt:"Question Repeating",class:"responsive-image",style:{width:"80%"}})],-1)),t[34]||(t[34]=(0,i.Lk)("div",{class:"solution-item"},[(0,i.Lk)("h4",null,"1. Question Repeating"),(0,i.Lk)("p",null,' We attach the original question to the end of the refinement prompt to reduce recency bias. For example: "Are you sure? Think and answer again." → "Are you sure? Think and answer again. Is human a kind of animals?" ')],-1)),t[35]||(t[35]=(0,i.Lk)("div",{class:"solution-item"},[(0,i.Lk)("h4",null,"2. Low-cost Supervised Fine-Tuning (SFT)"),(0,i.Lk)("p",null," We fine-tune models with extremely few samples (4 for Llama, 10 for GPT) selected from correct→wrong cases, without introducing external knowledge. The cost is only $0.004 and 3 minutes. ")],-1)),t[36]||(t[36]=(0,i.Lk)("h4",null,"Key Results",-1)),t[37]||(t[37]=(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Both strategies significantly reduce self-correction failures in Yes/No questions"),(0,i.Lk)("li",null,"SFT almost eliminates all correct→wrong cases"),(0,i.Lk)("li",null,"Models fine-tuned on Yes/No questions can generalize to complex tasks")],-1)),(0,i.bF)(X,{data:M,style:{width:"100%"},border:""},{default:(0,i.k6)((function(){return[(0,i.bF)(O,{prop:"model",label:"Model",align:"center"}),(0,i.bF)(O,{prop:"acc1",label:"ACC₁ (↓ΔACC) (%)",align:"center"}),(0,i.bF)(O,{prop:"overturned",label:"✓→✗ (%)",align:"center"},{default:(0,i.k6)((function(e){return[(0,i.eW)((0,o.v_)(e.row.overturned),1)]})),_:1})]})),_:1}),t[38]||(t[38]=(0,i.Lk)("p",{class:"table-caption"},"Table 2: Alleviating self-correction failure on Yes/No question answering task.",-1))])]),t[40]||(t[40]=(0,i.Lk)("div",{class:"section",id:"resources"},[(0,i.Lk)("h3",null,[(0,i.Lk)("span",{class:"section-title"},"Resources")]),(0,i.Lk)("div",{class:"section-content"},[(0,i.Lk)("p",null," Access our code repository through the following links: "),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,[(0,i.Lk)("a",{href:"https://anonymous.4open.science/r/SC-15FB/",target:"_blank"},"Project Code")])])])],-1))]})),_:1})]})),_:1})])])}}});var W=t(71241);const B=(0,W.A)(M,[["__scopeId","data-v-3a126768"]]),G=B},66251:(e,n,t)=>{e.exports=t.p+"3e1538bfa0c96da4.mov"},19769:(e,n,t)=>{e.exports=t.p+"4bc3990686a5c5ec.mov"},71482:(e,n,t)=>{e.exports=t.p+"89dec1d98a408cd3.mov"},28522:(e,n,t)=>{e.exports=t.p+"24d63d828b96e0de.mov"}}]);
//# sourceMappingURL=403.10b3efc3.js.map