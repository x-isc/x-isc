{"version":3,"file":"js/760.670a34d1.js","mappings":"0gBASMA,EAAa,CAAEC,MAAO,gBACtBC,EAAa,CAAED,MAAO,0BACtBE,EAAa,CAAEF,MAAO,iBACtBG,EAAa,CAAEH,MAAO,iBACtBI,EAAa,CAAEJ,MAAO,uBACtBK,EAAa,CAAC,WACdC,EAAa,CAAEN,MAAO,cACtBO,EAAa,CAAEP,MAAO,YACtBQ,EAAa,CAAER,MAAO,gBACtBS,EAAc,CAAC,OACfC,EAAc,CAAEV,MAAO,0BACvBW,EAAc,CAClBX,MAAO,UACPY,GAAI,YAEAC,EAAc,CAAEb,MAAO,mBACvBc,EAAc,CAClBd,MAAO,UACPY,GAAI,WAEAG,EAAc,CAAEf,MAAO,mBACvBgB,EAAc,CAAEC,MAAO,CAAC,QAAU,OAAO,kBAAkB,WAC3DC,EAAc,CAClBlB,MAAO,UACPY,GAAI,kBAEAO,EAAc,CAAEnB,MAAO,mBACvBoB,EAAc,CAAEpB,MAAO,cACvBqB,EAAc,CAAErB,MAAO,cACvBsB,EAAc,CAAEtB,MAAO,cACvBuB,EAAc,CAClBvB,MAAO,UACPY,GAAI,eAEAY,EAAc,CAAExB,MAAO,mBACvByB,EAAc,CAAER,MAAO,CAAC,QAAU,OAAO,kBAAkB,WAC3DS,EAAc,CAAET,MAAO,CAAC,QAAU,OAAO,kBAAkB,WAIjE,SAA4BU,EAAAA,EAAAA,IAAiB,CAC3CC,OAAQ,cACRC,MAAK,SAACC,GC8WN,IAAMC,EAAY,CAChB,CACEC,MAAO,qBACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,kBACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,aACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,oBACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,eACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,aACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,aACPC,KAAM,cACNC,WAAY,SAIVC,EAAe,CACnB,CACEH,MAAO,SACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,uBACPC,KAAM,cACNC,WAAY,OAEd,CACEF,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,MAAOC,MAAM,GAC3CJ,WAAY,CAAEE,MAAO,IAAKE,MAAM,IAElC,CACEN,MAAO,gBACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,uBACPC,KAAM,cACNC,WAAY,QAEd,CACEF,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,OAAQC,MAAM,GAC5CJ,WAAY,CAAEE,MAAO,IAAKE,MAAM,IAElC,CACEN,MAAO,eACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,uBACPC,KAAM,eACNC,WAAY,QAEd,CACEF,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,OAAQC,MAAM,GAC5CJ,WAAY,CAAEE,MAAO,IAAKE,MAAM,KAI9BC,EAAiB,CACrB,CACEC,KAAM,kBACNR,MAAO,SACPC,KAAM,eACNC,WAAY,QAEd,CACEM,KAAM,kBACNR,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,QAASC,MAAM,GAC7CJ,WAAY,CAAEE,MAAO,OAAQE,MAAM,IAErC,CACEE,KAAM,kBACNR,MAAO,gBACPC,KAAM,aACNC,WAAY,QAEd,CACEM,KAAM,kBACNR,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,OAAQC,MAAM,GAC5CJ,WAAY,CAAEE,MAAO,OAAQE,MAAM,IAErC,CACEE,KAAM,YACNR,MAAO,SACPC,KAAM,cACNC,WAAY,QAEd,CACEM,KAAM,YACNR,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,OAAQC,MAAM,GAC5CJ,WAAY,CAAEE,MAAO,MAAOE,MAAM,IAEpC,CACEE,KAAM,YACNR,MAAO,gBACPC,KAAM,cACNC,WAAY,QAEd,CACEM,KAAM,YACNR,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,OAAQC,MAAM,GAC5CJ,WAAY,CAAEE,MAAO,OAAQE,MAAM,IAErC,CACEE,KAAM,cACNR,MAAO,SACPC,KAAM,cACNC,WAAY,QAEd,CACEM,KAAM,cACNR,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,OAAQC,MAAM,GAC5CJ,WAAY,CAAEE,MAAO,MAAOE,MAAM,IAEpC,CACEE,KAAM,cACNR,MAAO,gBACPC,KAAM,eACNC,WAAY,QAEd,CACEM,KAAM,cACNR,MAAO,QACPC,KAAM,CAAEG,MAAO,OAAQC,MAAO,OAAQC,MAAM,GAC5CJ,WAAY,CAAEE,MAAO,OAAQE,MAAM,KAIjCG,EAAkB,SAACC,GACvB,IAAMC,EAAUC,SAASC,eAAeH,GACpCC,GACFA,EAAQG,eAAe,CAAEC,SAAU,UAEvC,EAGMC,EAAU,IAAIC,IAAI,cAA6CC,KAC/DC,EAAc,IAAIF,IAAI,cAAkDC,KACxEE,EAAU,IAAIH,IAAI,cAA6CC,KAC/DG,EAAc,IAAIJ,IAAI,cAAkDC,KAExEI,EAAe,CACnB,CACElB,MAAO,KACPmB,MAAO,+BACPvB,MAAO,0BACPwB,SAAU,+DACVC,IAAKT,GAEP,CACEZ,MAAO,UACPmB,MAAO,8BACPvB,MAAO,+BACPwB,SAAU,iCACVC,IAAKN,GAEP,CACEf,MAAO,KACPmB,MAAO,+BACPvB,MAAO,0BACPwB,SAAU,6CACVC,IAAKL,GAEP,CACEhB,MAAO,UACPmB,MAAO,yBACPvB,MAAO,+BACPwB,SAAU,8BACVC,IAAKJ,IAIHK,GAAgBC,EAAAA,EAAAA,IAAI,MAEpBC,GAAkBC,EAAAA,EAAAA,KAAS,WAC/B,IAAMC,EAASR,EAAaS,MAAK,SAAAC,GAAG,OAAIA,EAAI5B,QAAUsB,EAActB,KAAK,IACzE,OAAO0B,EAASA,EAAOL,IAAM,EAC/B,IDxWF,OAAO,SAACQ,EAAUC,GAChB,IAAMC,GAA0BC,EAAAA,EAAAA,IAAkB,gBAC5CC,GAAqBD,EAAAA,EAAAA,IAAkB,WACvCE,GAAoBF,EAAAA,EAAAA,IAAkB,UACtCG,GAAoBH,EAAAA,EAAAA,IAAkB,UACtCI,GAA6BJ,EAAAA,EAAAA,IAAkB,mBAC/CK,GAAsBL,EAAAA,EAAAA,IAAkB,YAE9C,OAAQM,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoB,MAAO5E,EAAY,EAC3D6E,EAAAA,EAAAA,IAAaP,EAAoB,CAC/BQ,KAAM,aACN,mBAAoB,mBACpB,aAAc,OACd,oBAAqB,QACpB,CACDC,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaT,EAAyB,CAAEa,MAAO,KAAO,CACpDF,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDe,EAAAA,EAAAA,IAAoB,OAAQ,CAAEhE,MAAO,CAAC,cAAc,QAAU,SAAU,IACxE,IACFiE,EAAG,KAELN,EAAAA,EAAAA,IAAaT,EAAyB,CACpCgB,QAASjB,EAAO,KAAOA,EAAO,GAAK,SAACkB,GAAW,OAAM3C,EAAgB,WAAW,IAC/E,CACDqC,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDmB,EAAAA,EAAAA,IAAiB,aACjB,IACFH,EAAG,KAELN,EAAAA,EAAAA,IAAaT,EAAyB,CACpCgB,QAASjB,EAAO,KAAOA,EAAO,GAAK,SAACkB,GAAW,OAAM3C,EAAgB,UAAU,IAC9E,CACDqC,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDmB,EAAAA,EAAAA,IAAiB,yCACjB,IACFH,EAAG,KAELN,EAAAA,EAAAA,IAAaT,EAAyB,CACpCgB,QAASjB,EAAO,KAAOA,EAAO,GAAK,SAACkB,GAAW,OAAM3C,EAAgB,iBAAiB,IACrF,CACDqC,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDmB,EAAAA,EAAAA,IAAiB,mBACjB,IACFH,EAAG,KAELN,EAAAA,EAAAA,IAAaT,EAAyB,CACpCgB,QAASjB,EAAO,KAAOA,EAAO,GAAK,SAACkB,GAAW,OAAM3C,EAAgB,cAAc,IAClF,CACDqC,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,KAAOA,EAAO,GAAK,EAChDmB,EAAAA,EAAAA,IAAiB,gBACjB,IACFH,EAAG,KAELN,EAAAA,EAAAA,IAAaT,EAAyB,CACpCgB,QAASjB,EAAO,KAAOA,EAAO,GAAK,SAACkB,GAAW,OAAM3C,EAAgB,YAAY,IAChF,CACDqC,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDmB,EAAAA,EAAAA,IAAiB,cACjB,IACFH,EAAG,IAEN,IACDA,EAAG,IAELhB,EAAO,MAAQA,EAAO,KAAMoB,EAAAA,EAAAA,IAAmB,w+CAA+gD,KAC9jDL,EAAAA,EAAAA,IAAoB,MAAOhF,EAAY,EACrC2E,EAAAA,EAAAA,IAAaL,EAAmB,CAAEgB,QAAS,UAAY,CACrDT,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,KAAM,CAAEjF,MAAO,uBAAyB,EAC1DiF,EAAAA,EAAAA,IAAoB,OAAQ,CAAEjF,MAAO,iBAAmB,6DACtD,IACJ,IACFkF,EAAG,IAEN,IACDA,EAAG,OAGPD,EAAAA,EAAAA,IAAoB,MAAO/E,EAAY,EACrC0E,EAAAA,EAAAA,IAAaL,EAAmB,CAAEkB,OAAQ,IAAM,CAC9CX,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,KACxCZ,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,GAAK,CAC3CV,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBE,EAAAA,EAAAA,IAAoB,MAAO9E,EAAY,EACrC8E,EAAAA,EAAAA,IAAoB,MAAO7E,EAAY,CACrC8D,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,uBAAyB,8BAA+B,MACvH0E,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoBe,EAAAA,GAAW,MAAMC,EAAAA,EAAAA,IAAYrC,GAAc,SAACQ,GAC7E,OAAOmB,EAAAA,EAAAA,IAAoB,MAAO,CAChCW,IAAK9B,EAAO1B,MACZpC,OAAO6F,EAAAA,EAAAA,IAAgB,CAAC,oBAAqB,CAAEC,OAAQpC,EAActB,QAAU0B,EAAO1B,SACtF+C,QAAS,SAACC,GAAW,OAAM1B,EAActB,MAAQ0B,EAAO1B,KAAK,GAC5D,EACD6C,EAAAA,EAAAA,IAAoB,MAAO3E,GAAYyF,EAAAA,EAAAA,IAAiBjC,EAAO9B,OAAQ,IACvEiD,EAAAA,EAAAA,IAAoB,MAAO1E,GAAYwF,EAAAA,EAAAA,IAAiBjC,EAAON,UAAW,IACzE,GAAInD,EACT,IAAI,SAGT,IACD6E,EAAG,KAELN,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBE,EAAAA,EAAAA,IAAoB,MAAOzE,EAAY,CACpCoD,EAAgBxB,QACZsC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoB,QAAS,CAC1CiB,IAAK,EACLnC,IAAKG,EAAgBxB,MACrB4D,SAAU,GACVhG,MAAO,cACN,iDAAkD,EAAGS,KACxDwF,EAAAA,EAAAA,IAAoB,IAAI,KAE/B,IACDf,EAAG,IAEN,IACDA,EAAG,OAGPD,EAAAA,EAAAA,IAAoB,MAAOvE,EAAa,EACtCkE,EAAAA,EAAAA,IAAaL,EAAmB,CAAEgB,QAAS,UAAY,CACrDT,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBE,EAAAA,EAAAA,IAAoB,MAAOtE,EAAa,CACtCuD,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAEjF,MAAO,iBAAmB,cACtD,KACJiF,EAAAA,EAAAA,IAAoB,MAAOpE,EAAa,EACtC+D,EAAAA,EAAAA,IAAaL,EAAmB,CAAEkB,OAAQ,IAAM,CAC9CX,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,KACxCZ,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,g+BAAi+B,IAChgC,IACFC,EAAG,KAELN,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBxB,IAAKyC,EACLC,IAAK,WACLnG,MAAO,mCACN,MAAO,IACV,IACFkF,EAAG,IAEN,IACDA,EAAG,SAITD,EAAAA,EAAAA,IAAoB,MAAOnE,EAAa,CACtCoD,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAEjF,MAAO,iBAAmB,0CACtD,KACJiF,EAAAA,EAAAA,IAAoB,MAAOlE,EAAa,CACtCmD,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,yTAA0T,IACrXf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,wBAAyB,IACrFf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,mGAAoG,KAC/JA,EAAAA,EAAAA,IAAoB,MAAOjE,EAAa,EACtC4D,EAAAA,EAAAA,IAAaH,EAAqB,CAChC7D,GAAI,cACJwF,KAAMrE,EACNd,MAAO,CAAC,MAAQ,QACf,CACD6D,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,QACN9C,MAAO,QACP+C,MAAO,YAET1B,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,OACN9C,MAAO,mBACP+C,MAAO,YAET1B,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,aACN9C,MAAO,UACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,EAC3BlB,EAAAA,EAAAA,KAAiBU,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAItE,YAAa,GAC1D,IACDgD,EAAG,IAEN,IACDA,EAAG,MAGPhB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,CAAEjF,MAAO,iBAAmB,+EAAgF,IACjKkE,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,mBAAqB,EACnFiF,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCI,EAAAA,EAAAA,IAAiB,4JACf,SAGRJ,EAAAA,EAAAA,IAAoB,MAAO/D,EAAa,CACtCgD,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAEjF,MAAO,iBAAmB,oBACtD,KACJiF,EAAAA,EAAAA,IAAoB,MAAO9D,EAAa,CACtC+C,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,2HAA4H,KACvLA,EAAAA,EAAAA,IAAoB,MAAO7D,EAAa,EACtCwD,EAAAA,EAAAA,IAAaL,EAAmB,CAAEkB,OAAQ,IAAM,CAC9CX,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,+BAAgC,IAChEA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,iJAAkJ,IACjLA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,0EAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,sHAC9B,IACJ,IACFC,EAAG,KAELN,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBxB,IAAKgD,EACLN,IAAK,+BACLnG,MAAO,gBACN,MAAO,IACV,IACFkF,EAAG,IAEN,IACDA,EAAG,IAELhB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,mBAAqB,EACnFiF,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCI,EAAAA,EAAAA,IAAiB,mNACf,OAENJ,EAAAA,EAAAA,IAAoB,MAAO5D,EAAa,EACtCuD,EAAAA,EAAAA,IAAaL,EAAmB,CAAEkB,OAAQ,IAAM,CAC9CX,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,8CAA+C,IAC/EA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,wJAAyJ,IACxLA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,gGAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,uFAC9B,IACJ,IACFC,EAAG,KAELN,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,KACxCZ,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBxB,IAAKiD,EACLP,IAAK,6BACLnG,MAAO,gBACN,MAAO,IACV,IACFkF,EAAG,IAEN,IACDA,EAAG,IAELhB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,mBAAqB,EACnFiF,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCI,EAAAA,EAAAA,IAAiB,oHACf,OAENJ,EAAAA,EAAAA,IAAoB,MAAO3D,EAAa,EACtCsD,EAAAA,EAAAA,IAAaL,EAAmB,CAAEkB,OAAQ,IAAM,CAC9CX,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,yCAA0C,IAC1EA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,kHAAmH,IAClJA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,SAAU,KAAM,kBACpCI,EAAAA,EAAAA,IAAiB,2FAEnBJ,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,SAAU,KAAM,wBACpCI,EAAAA,EAAAA,IAAiB,oEAEnBJ,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,SAAU,KAAM,wBACpCI,EAAAA,EAAAA,IAAiB,2DAEjB,IACJ,IACFH,EAAG,KAELN,EAAAA,EAAAA,IAAaN,EAAmB,CAAEkB,KAAM,IAAM,CAC5CV,SAASC,EAAAA,EAAAA,KAAS,kBAAMb,EAAO,MAAQA,EAAO,IAAM,EAClDe,EAAAA,EAAAA,IAAoB,MAAO,CACzBxB,IAAKkD,EACLR,IAAK,yBACLnG,MAAO,gBACN,MAAO,IACV,IACFkF,EAAG,IAEN,IACDA,EAAG,IAELhB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,mBAAqB,EACnFiF,EAAAA,EAAAA,IAAoB,SAAU,KAAM,mBACpCI,EAAAA,EAAAA,IAAiB,gXACf,WAIVJ,EAAAA,EAAAA,IAAoB,MAAO1D,EAAa,CACtC2C,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,OAAQ,CAAEjF,MAAO,iBAAmB,iBACtD,KACJiF,EAAAA,EAAAA,IAAoB,MAAOzD,EAAa,CACtC0C,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,KAAM,iMAAkM,IAC7Pf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEhE,MAAO,CAAC,aAAa,WAAa,EACzFgE,EAAAA,EAAAA,IAAoB,MAAO,CACzBxB,IAAKmD,EACLT,IAAK,qBACLnG,MAAO,mBACPiB,MAAO,CAAC,MAAQ,WAEhB,IACJiD,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,iBAAmB,EACjFiF,EAAAA,EAAAA,IAAoB,KAAM,KAAM,0BAChCA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,8NAC7B,IACJf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,iBAAmB,EACjFiF,EAAAA,EAAAA,IAAoB,KAAM,KAAM,6CAChCA,EAAAA,EAAAA,IAAoB,IAAK,KAAM,wLAC7B,IACJf,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,eAAgB,IAC5Ef,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC1DA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,sFAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,wCAChCA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,2EAC9B,KACJA,EAAAA,EAAAA,IAAoB,MAAOxD,EAAa,EACtCmD,EAAAA,EAAAA,IAAaH,EAAqB,CAChC7D,GAAI,iBACJwF,KAAMjE,EACNlB,MAAO,CAAC,MAAQ,OAChB,iBAAkB,SAACuF,GAAG,OAAKA,EAAIK,WAAa,gBAAkB,EAAE,GAC/D,CACD/B,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,QACN9C,MAAO,QACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,EAC3BtB,EAAAA,EAAAA,IAAoB,OAAQ,CAC1BjF,OAAO6F,EAAAA,EAAAA,IAAgB,CAAE,YAAaU,EAAMC,IAAIxE,MAAM8E,SAAS,WAC9Df,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIxE,OAAQ,GACvC,IACDkD,EAAG,KAELN,EAAAA,EAAAA,IAAaJ,EAA4B,CACvCjB,MAAO,mBACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,CACA,YAA1BQ,EAAAA,EAAAA,GAAOR,EAAMC,IAAIvE,QACbyC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoB,OAAQ,CACzCiB,IAAK,EACL5F,OAAO6F,EAAAA,EAAAA,IAAgB,CAAE,YAAaU,EAAMC,IAAIvE,KAAKK,SACpDyD,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIvE,KAAKG,OAAS,MAAO2D,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIvE,KAAKI,OAAS,KAAM,MACjGqC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoBe,EAAAA,GAAW,CAAEE,IAAK,GAAK,EACxDP,EAAAA,EAAAA,KAAiBU,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIvE,MAAO,IAClD,KACR,IACDiD,EAAG,KAELN,EAAAA,EAAAA,IAAaJ,EAA4B,CACvCjB,MAAO,UACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,CACM,YAAhCQ,EAAAA,EAAAA,GAAOR,EAAMC,IAAItE,cACbwC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoB,OAAQ,CACzCiB,IAAK,EACL5F,OAAO6F,EAAAA,EAAAA,IAAgB,CAAE,YAAaU,EAAMC,IAAItE,WAAWI,SAC1DyD,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAItE,WAAWE,OAAQ,MAChDsC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoBe,EAAAA,GAAW,CAAEE,IAAK,GAAK,EACxDP,EAAAA,EAAAA,KAAiBU,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAItE,YAAa,IACxD,KACR,IACDgD,EAAG,IAEN,IACDA,EAAG,GACF,EAAG,CAAC,qBAEThB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,CAAEjF,MAAO,4CAA8C,yOAA0O,KACtViF,EAAAA,EAAAA,IAAoB,MAAOvD,EAAa,EACtCkD,EAAAA,EAAAA,IAAaH,EAAqB,CAChC7D,GAAI,mBACJwF,KAAM7D,EACNtB,MAAO,CAAC,MAAQ,OAChB,iBAAkB,SAACuF,GAAG,OAAKA,EAAIK,WAAa,gBAAkB,EAAE,GAC/D,CACD/B,SAASC,EAAAA,EAAAA,KAAS,iBAAM,EACtBH,EAAAA,EAAAA,IAAaJ,EAA4B,CACvC6B,KAAM,OACN9C,MAAO,OACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,EAC3BtB,EAAAA,EAAAA,IAAoB,OAAQ,MAAMc,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIhE,MAAO,GACrE,IACD0C,EAAG,KAELN,EAAAA,EAAAA,IAAaJ,EAA4B,CACvCjB,MAAO,QACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,EAC3BtB,EAAAA,EAAAA,IAAoB,OAAQ,CAC1BjF,OAAO6F,EAAAA,EAAAA,IAAgB,CAAE,YAAaU,EAAMC,IAAIxE,MAAM8E,SAAS,WAC9Df,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIxE,OAAQ,GACvC,IACDkD,EAAG,KAELN,EAAAA,EAAAA,IAAaJ,EAA4B,CACvCjB,MAAO,mBACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,CACA,YAA1BQ,EAAAA,EAAAA,GAAOR,EAAMC,IAAIvE,QACbyC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoB,OAAQ,CACzCiB,IAAK,EACL5F,OAAO6F,EAAAA,EAAAA,IAAgB,CAAE,YAAaU,EAAMC,IAAIvE,KAAKK,SACpDyD,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIvE,KAAKG,OAAS,MAAO2D,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIvE,KAAKI,OAAS,KAAM,MACjGqC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoBe,EAAAA,GAAW,CAAEE,IAAK,GAAK,EACxDP,EAAAA,EAAAA,KAAiBU,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAIvE,MAAO,IAClD,KACR,IACDiD,EAAG,KAELN,EAAAA,EAAAA,IAAaJ,EAA4B,CACvCjB,MAAO,UACP+C,MAAO,UACN,CACDxB,SAASC,EAAAA,EAAAA,KAAS,SAACwB,GAAK,MAAK,CACM,YAAhCQ,EAAAA,EAAAA,GAAOR,EAAMC,IAAItE,cACbwC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoB,OAAQ,CACzCiB,IAAK,EACL5F,OAAO6F,EAAAA,EAAAA,IAAgB,CAAE,YAAaU,EAAMC,IAAItE,WAAWI,SAC1DyD,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAItE,WAAWE,OAAQ,MAChDsC,EAAAA,EAAAA,OAAcC,EAAAA,EAAAA,IAAoBe,EAAAA,GAAW,CAAEE,IAAK,GAAK,EACxDP,EAAAA,EAAAA,KAAiBU,EAAAA,EAAAA,IAAiBQ,EAAMC,IAAItE,YAAa,IACxD,KACR,IACDgD,EAAG,IAEN,IACDA,EAAG,GACF,EAAG,CAAC,qBAEThB,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,IAAK,CAAEjF,MAAO,iBAAmB,wMAAyM,QAG9RkE,EAAO,MAAQA,EAAO,KAAMe,EAAAA,EAAAA,IAAoB,MAAO,CACrDjF,MAAO,UACPY,GAAI,aACH,EACDqE,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,OAAQ,CAAEjF,MAAO,iBAAmB,gBAE1DiF,EAAAA,EAAAA,IAAoB,MAAO,CAAEjF,MAAO,mBAAqB,EACvDiF,EAAAA,EAAAA,IAAoB,IAAK,KAAM,8DAC/BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,KAAM,KAAM,EAC9BA,EAAAA,EAAAA,IAAoB,IAAK,CACvB/B,KAAM,6CACN8D,OAAQ,UACP,wBAIP,IACL,IACD9B,EAAG,IAEN,IACDA,EAAG,OAIX,CACA,I,eEzvBA,MAAM+B,GAA2B,OAAgB,EAAQ,CAAC,CAAC,YAAY,qBAEvE,G,yOCPA,IAAIC,EAAI,EAAQ,OACZC,EAAa,EAAQ,OACrBC,EAAyB,EAAQ,OAIrCF,EAAE,CAAEF,OAAQ,SAAUK,OAAO,EAAMC,OAAQF,EAAuB,SAAW,CAC3E9E,KAAM,WACJ,OAAO6E,EAAWI,KAAM,IAAK,GAAI,GACnC,G","sources":["webpack://X-ISC/./src/views/ProjectView.vue?cc76","webpack://X-ISC/./src/views/ProjectView.vue","webpack://X-ISC/./src/views/ProjectView.vue?09a1","webpack://X-ISC/./node_modules/core-js/modules/es.string.bold.js"],"sourcesContent":["import { defineComponent as _defineComponent } from 'vue'\nimport { createElementVNode as _createElementVNode, resolveComponent as _resolveComponent, withCtx as _withCtx, createVNode as _createVNode, createTextVNode as _createTextVNode, openBlock as _openBlock, createElementBlock as _createElementBlock, renderList as _renderList, Fragment as _Fragment, toDisplayString as _toDisplayString, normalizeClass as _normalizeClass, createCommentVNode as _createCommentVNode, createStaticVNode as _createStaticVNode } from \"vue\"\nimport _imports_0 from '@/figures/overviewf3.png'\nimport _imports_1 from '@/figures/internal_confidence.png'\nimport _imports_2 from '@/figures/case.png'\nimport _imports_3 from '@/figures/humanCognitiveBiasf.png'\nimport _imports_4 from '@/figures/mergedMitigation2.png'\n\n\nconst _hoisted_1 = { class: \"project-page\" }\nconst _hoisted_2 = { class: \"container main-content\" }\nconst _hoisted_3 = { class: \"video-section\" }\nconst _hoisted_4 = { class: \"video-options\" }\nconst _hoisted_5 = { class: \"video-selector-list\" }\nconst _hoisted_6 = [\"onClick\"]\nconst _hoisted_7 = { class: \"model-name\" }\nconst _hoisted_8 = { class: \"question\" }\nconst _hoisted_9 = { class: \"video-player\" }\nconst _hoisted_10 = [\"src\"]\nconst _hoisted_11 = { class: \"container main-content\" }\nconst _hoisted_12 = {\n  class: \"section\",\n  id: \"abstract\"\n}\nconst _hoisted_13 = { class: \"section-content\" }\nconst _hoisted_14 = {\n  class: \"section\",\n  id: \"failure\"\n}\nconst _hoisted_15 = { class: \"section-content\" }\nconst _hoisted_16 = { style: {\"display\":\"flex\",\"justify-content\":\"center\"} }\nconst _hoisted_17 = {\n  class: \"section\",\n  id: \"interpretation\"\n}\nconst _hoisted_18 = { class: \"section-content\" }\nconst _hoisted_19 = { class: \"method-box\" }\nconst _hoisted_20 = { class: \"method-box\" }\nconst _hoisted_21 = { class: \"method-box\" }\nconst _hoisted_22 = {\n  class: \"section\",\n  id: \"alleviation\"\n}\nconst _hoisted_23 = { class: \"section-content\" }\nconst _hoisted_24 = { style: {\"display\":\"flex\",\"justify-content\":\"center\"} }\nconst _hoisted_25 = { style: {\"display\":\"flex\",\"justify-content\":\"center\"} }\n\nimport { ref, computed } from 'vue';\n  \nexport default /*@__PURE__*/_defineComponent({\n  __name: 'ProjectView',\n  setup(__props) {\n\n  // No additional scripts needed for static content\n  \n  // Sample Data for Tables\n  const boolqData = [\n    { \n      model: 'ChatGPT o1-preview', \n      acc1: '78.7 (↓4.9)', \n      overturned: '13.2' \n    },\n    { \n      model: 'ChatGPT o1-mini', \n      acc1: '74.1 (↓4.2)', \n      overturned: '15.6' \n    },\n    { \n      model: 'ChatGPT 4o', \n      acc1: '79.2 (↓4.9)', \n      overturned: '11.3' \n    },\n    { \n      model: 'ChatGPT 3.5-turbo', \n      acc1: '62.5 (↓12.1)', \n      overturned: '34.0' \n    },\n    { \n      model: 'Llama-3.1-8B', \n      acc1: '49.2 (↓20.4)', \n      overturned: '58.8' \n    },\n    { \n      model: 'Llama-3-8B', \n      acc1: '50.1 (↓20.3)', \n      overturned: '58.2' \n    },\n    { \n      model: 'Llama-2-7B', \n      acc1: '52.8 (↓8.7)', \n      overturned: '26.5' \n    }\n  ];\n  \n  const mitigateData = [\n    { \n      model: 'GPT-4o', \n      acc1: '79.2 (↓4.9)', \n      overturned: '11.3',\n    },\n    { \n      model: '+ Question repeating', \n      acc1: '83.6 (↓0.5)', \n      overturned: '6.0',\n    },\n    { \n      model: '+ SFT', \n      acc1: { value: '87.7', delta: '4.1', bold: true }, \n      overturned: { value: '0', bold: true },\n    },\n    { \n      model: 'GPT-3.5-turbo', \n      acc1: '62.5 (↓12.1)', \n      overturned: '34.0',\n    },\n    { \n      model: '+ Question repeating', \n      acc1: '67.4 (↓7.2)', \n      overturned: '23.1',\n    },\n    { \n      model: '+ SFT', \n      acc1: { value: '76.2', delta: '↑1.6', bold: true }, \n      overturned: { value: '0', bold: true },\n    },\n    { \n      model: 'Llama-3.1-8B', \n      acc1: '49.2 (↓20.4)', \n      overturned: '58.8',\n    },\n    { \n      model: '+ Question repeating', \n      acc1: '52.4 (↓17.2)', \n      overturned: '52.8',\n    },\n    { \n      model: '+ SFT', \n      acc1: { value: '70.3', delta: '↓0.7', bold: true }, \n      overturned: { value: '0', bold: true },\n    }\n  ];\n  \n  const generalizeData = [\n    {\n      task: 'Decision Making',\n      model: 'GPT-4o',\n      acc1: '14.2 (↓20.9)',\n      overturned: '76.6',\n    },\n    {\n      task: 'Decision Making', \n      model: '+ SFT',\n      acc1: { value: '14.9', delta: '↓20.2', bold: true },\n      overturned: { value: '68.1', bold: true },\n    },\n    {\n      task: 'Decision Making',\n      model: 'GPT-3.5-turbo',\n      acc1: '7.5 (↓5.2)',\n      overturned: '76.5',\n    },\n    {\n      task: 'Decision Making',\n      model: '+ SFT',\n      acc1: { value: '17.9', delta: '↑5.2', bold: true },\n      overturned: { value: '41.2', bold: true },\n    },\n    {\n      task: 'Reasoning',\n      model: 'GPT-4o',\n      acc1: '65.0 (↓2.0)',\n      overturned: '17.9',\n    },\n    {\n      task: 'Reasoning',\n      model: '+ SFT',\n      acc1: { value: '68.0', delta: '↑1.0', bold: true },\n      overturned: { value: '6.0', bold: true },\n    },\n    {\n      task: 'Reasoning',\n      model: 'GPT-3.5-turbo',\n      acc1: '55.0 (↓6.0)',\n      overturned: '19.7',\n    },\n    {\n      task: 'Reasoning',\n      model: '+ SFT',\n      acc1: { value: '59.0', delta: '↓2.0', bold: true },\n      overturned: { value: '13.1', bold: true },\n    },\n    {\n      task: 'Programming',\n      model: 'GPT-4o',\n      acc1: '72.6 (↓6.8)',\n      overturned: '21.9',\n    },\n    {\n      task: 'Programming',\n      model: '+ SFT',\n      acc1: { value: '82.6', delta: '↑3.2', bold: true },\n      overturned: { value: '7.0', bold: true },\n    },\n    {\n      task: 'Programming',\n      model: 'GPT-3.5-turbo',\n      acc1: '50.9 (↓10.6)',\n      overturned: '28.3',\n    },\n    {\n      task: 'Programming',\n      model: '+ SFT',\n      acc1: { value: '58.3', delta: '↓3.2', bold: true },\n      overturned: { value: '25.3', bold: true },\n    }\n  ];\n  \n  const scrollToSection = (sectionId: string) => {\n    const element = document.getElementById(sectionId);\n    if (element) {\n      element.scrollIntoView({ behavior: 'smooth' });\n    }\n  };\n  \n  const video4o = new URL('@/figures/4o_noaudio.mov', import.meta.url).href\n  const video4oMini = new URL('@/figures/4o-mini_noaudio.mov', import.meta.url).href\n  const videoO1 = new URL('@/figures/o1_noaudio.mov', import.meta.url).href\n  const videoO1Mini = new URL('@/figures/o1-mini_noaudio.mov', import.meta.url).href\n  \n  const videoOptions = [\n    {\n      value: '4o',\n      label: 'GPT-4o - Population Question',\n      model: 'ChatGPT 4o (2024.12.17)',\n      question: 'There are over 1000 countries in the world, is that correct?',\n      src: video4o\n    },\n    {\n      value: '4o-mini',\n      label: 'GPT-4o - Moon Jump Question',\n      model: 'ChatGPT 4o mini (2024.12.17)',\n      question: 'Can I jump from Earth to Moon?',\n      src: video4oMini\n    },\n    {\n      value: 'o1',\n      label: 'GPT-o1 - Population Question',\n      model: 'ChatGPT o1 (2024.12.17)',\n      question: 'Does China has more population than India?',\n      src: videoO1\n    },\n    {\n      value: 'o1-mini',\n      label: 'GPT-o1 - Arms Question',\n      model: 'ChatGPT o1-mini (2024.12.17)',\n      question: 'Does human have three arms?',\n      src: videoO1Mini\n    }\n  ];\n  \n  const selectedVideo = ref('4o');\n  \n  const currentVideoSrc = computed(() => {\n    const option = videoOptions.find(opt => opt.value === selectedVideo.value);\n    return option ? option.src : '';\n  });\n  \nreturn (_ctx: any,_cache: any) => {\n  const _component_el_menu_item = _resolveComponent(\"el-menu-item\")!\n  const _component_el_menu = _resolveComponent(\"el-menu\")!\n  const _component_el_col = _resolveComponent(\"el-col\")!\n  const _component_el_row = _resolveComponent(\"el-row\")!\n  const _component_el_table_column = _resolveComponent(\"el-table-column\")!\n  const _component_el_table = _resolveComponent(\"el-table\")!\n\n  return (_openBlock(), _createElementBlock(\"div\", _hoisted_1, [\n    _createVNode(_component_el_menu, {\n      mode: \"horizontal\",\n      \"background-color\": 'rgb(140, 21, 21)',\n      \"text-color\": \"#fff\",\n      \"active-text-color\": \"#fff\"\n    }, {\n      default: _withCtx(() => [\n        _createVNode(_component_el_menu_item, { index: \"/\" }, {\n          default: _withCtx(() => _cache[5] || (_cache[5] = [\n            _createElementVNode(\"span\", { style: {\"font-weight\":\"800\"} }, \"X-ISC\", -1)\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[0] || (_cache[0] = ($event: any) => (scrollToSection('abstract')))\n        }, {\n          default: _withCtx(() => _cache[6] || (_cache[6] = [\n            _createTextVNode(\"Abstract\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[1] || (_cache[1] = ($event: any) => (scrollToSection('failure')))\n        }, {\n          default: _withCtx(() => _cache[7] || (_cache[7] = [\n            _createTextVNode(\"Failure of Intrinsic Self-Correction\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[2] || (_cache[2] = ($event: any) => (scrollToSection('interpretation')))\n        }, {\n          default: _withCtx(() => _cache[8] || (_cache[8] = [\n            _createTextVNode(\"Interpretation\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[3] || (_cache[3] = ($event: any) => (scrollToSection('alleviation')))\n        }, {\n          default: _withCtx(() => _cache[9] || (_cache[9] = [\n            _createTextVNode(\"Alleviation\")\n          ])),\n          _: 1\n        }),\n        _createVNode(_component_el_menu_item, {\n          onClick: _cache[4] || (_cache[4] = ($event: any) => (scrollToSection('resources')))\n        }, {\n          default: _withCtx(() => _cache[10] || (_cache[10] = [\n            _createTextVNode(\"Resources\")\n          ])),\n          _: 1\n        })\n      ]),\n      _: 1\n    }),\n    _cache[43] || (_cache[43] = _createStaticVNode(\"<div class=\\\"container header\\\" data-v-04cd88ca><h2 class=\\\"title\\\" data-v-04cd88ca>Understanding the Dark Side of LLMs&#39; Intrinsic Self-Correction</h2><h4 class=\\\"subtitle\\\" data-v-04cd88ca><span class=\\\"underline\\\" data-v-04cd88ca>Ex</span>plaining <span class=\\\"underline\\\" data-v-04cd88ca>I</span>ntrinsic <span class=\\\"underline\\\" data-v-04cd88ca>S</span>elf-<span class=\\\"underline\\\" data-v-04cd88ca>C</span>orrection (X-ISC) </h4><div class=\\\"author-info\\\" data-v-04cd88ca><span data-v-04cd88ca>Anonymous submission</span></div><div class=\\\"github-link-container\\\" data-v-04cd88ca><a href=\\\"https://anonymous.4open.science/r/SC-15FB/\\\" class=\\\"github-button\\\" target=\\\"_blank\\\" data-v-04cd88ca><i class=\\\"github-icon\\\" data-v-04cd88ca><svg xmlns=\\\"http://www.w3.org/2000/svg\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" viewBox=\\\"0 0 16 16\\\" data-v-04cd88ca><path d=\\\"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z\\\" data-v-04cd88ca></path></svg></i><span data-v-04cd88ca>Project Code</span></a></div></div>\", 1)),\n    _createElementVNode(\"div\", _hoisted_2, [\n      _createVNode(_component_el_row, { justify: \"center\" }, {\n        default: _withCtx(() => [\n          _createVNode(_component_el_col, { span: 20 }, {\n            default: _withCtx(() => _cache[11] || (_cache[11] = [\n              _createElementVNode(\"h3\", { class: \"video-section-title\" }, [\n                _createElementVNode(\"span\", { class: \"section-title\" }, \"A First Quick Glance for the Extremely Simple Questions\")\n              ], -1)\n            ])),\n            _: 1\n          })\n        ]),\n        _: 1\n      })\n    ]),\n    _createElementVNode(\"div\", _hoisted_3, [\n      _createVNode(_component_el_row, { gutter: 10 }, {\n        default: _withCtx(() => [\n          _createVNode(_component_el_col, { span: 1 }),\n          _createVNode(_component_el_col, { span: 7 }, {\n            default: _withCtx(() => [\n              _createElementVNode(\"div\", _hoisted_4, [\n                _createElementVNode(\"div\", _hoisted_5, [\n                  _cache[12] || (_cache[12] = _createElementVNode(\"div\", { class: \"video-option-header\" }, \" Select Model & Question: \", -1)),\n                  (_openBlock(), _createElementBlock(_Fragment, null, _renderList(videoOptions, (option) => {\n                    return _createElementVNode(\"div\", {\n                      key: option.value,\n                      class: _normalizeClass([\"video-option-item\", { active: selectedVideo.value === option.value }]),\n                      onClick: ($event: any) => (selectedVideo.value = option.value)\n                    }, [\n                      _createElementVNode(\"div\", _hoisted_7, _toDisplayString(option.model), 1),\n                      _createElementVNode(\"div\", _hoisted_8, _toDisplayString(option.question), 1)\n                    ], 10, _hoisted_6)\n                  }), 64))\n                ])\n              ])\n            ]),\n            _: 1\n          }),\n          _createVNode(_component_el_col, { span: 15 }, {\n            default: _withCtx(() => [\n              _createElementVNode(\"div\", _hoisted_9, [\n                (currentVideoSrc.value)\n                  ? (_openBlock(), _createElementBlock(\"video\", {\n                      key: 0,\n                      src: currentVideoSrc.value,\n                      controls: \"\",\n                      class: \"demo-video\"\n                    }, \" Your browser does not support the video tag. \", 8, _hoisted_10))\n                  : _createCommentVNode(\"\", true)\n              ])\n            ]),\n            _: 1\n          })\n        ]),\n        _: 1\n      })\n    ]),\n    _createElementVNode(\"div\", _hoisted_11, [\n      _createVNode(_component_el_row, { justify: \"center\" }, {\n        default: _withCtx(() => [\n          _createVNode(_component_el_col, { span: 20 }, {\n            default: _withCtx(() => [\n              _createElementVNode(\"div\", _hoisted_12, [\n                _cache[15] || (_cache[15] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Abstract\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_13, [\n                  _createVNode(_component_el_row, { gutter: 20 }, {\n                    default: _withCtx(() => [\n                      _createVNode(_component_el_col, { span: 1 }),\n                      _createVNode(_component_el_col, { span: 11 }, {\n                        default: _withCtx(() => _cache[13] || (_cache[13] = [\n                          _createElementVNode(\"p\", null, \" Intrinsic self-correction was proposed to improve LLMs' responses via feedback solely based on their inherent capability. However, recent works show that LLMs' intrinsic self-correction fails without oracle labels as feedback. In this paper, we aim to interpret LLMs' intrinsic self-correction for different tasks, especially for those failure cases? By including one simple task and three complex tasks with state-of-the-art (SOTA) LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B, and 3.1-8B), we design interpretation methods to reveal the dark side of SOTA LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1) cause LLMs to waver both intermedia and final answers and lead to prompt bias on simple factual questions; (2) introduce human-like cognitive bias on complex tasks. In light of our findings, we also provide two simple, low-cost, yet effective strategies for alleviation: question repeating and supervised fine-tuning. \", -1)\n                        ])),\n                        _: 1\n                      }),\n                      _createVNode(_component_el_col, { span: 10 }, {\n                        default: _withCtx(() => _cache[14] || (_cache[14] = [\n                          _createElementVNode(\"img\", {\n                            src: _imports_0,\n                            alt: \"Overview\",\n                            class: \"responsive-image abstract-image\"\n                          }, null, -1)\n                        ])),\n                        _: 1\n                      })\n                    ]),\n                    _: 1\n                  })\n                ])\n              ]),\n              _createElementVNode(\"div\", _hoisted_14, [\n                _cache[21] || (_cache[21] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Failure of Intrinsic Self-Correction\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_15, [\n                  _cache[16] || (_cache[16] = _createElementVNode(\"p\", null, \" Intrinsic self-correction mechanisms in state-of-the-art LLMs were expected to enhance performance by refining responses based solely on the model's inherent capabilities. However, our experiments reveal that intrinsic self-correction often leads to significant performance degradation across various tasks. \", -1)),\n                  _cache[17] || (_cache[17] = _createElementVNode(\"h4\", null, \"Experimental Results\", -1)),\n                  _cache[18] || (_cache[18] = _createElementVNode(\"p\", null, \"Below are the key experimental results demonstrating the failures of intrinsic self-correction:\", -1)),\n                  _createElementVNode(\"div\", _hoisted_16, [\n                    _createVNode(_component_el_table, {\n                      id: \"boolq-table\",\n                      data: boolqData,\n                      style: {\"width\":\"85%\"}\n                    }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_table_column, {\n                          prop: \"model\",\n                          label: \"Model\",\n                          align: \"center\"\n                        }),\n                        _createVNode(_component_el_table_column, {\n                          prop: \"acc1\",\n                          label: \"ACC₁ (↓ΔACC) (%)\",\n                          align: \"center\"\n                        }),\n                        _createVNode(_component_el_table_column, {\n                          prop: \"overturned\",\n                          label: \"✓→✗ (%)\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            _createTextVNode(_toDisplayString(scope.row.overturned), 1)\n                          ]),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    })\n                  ]),\n                  _cache[19] || (_cache[19] = _createElementVNode(\"p\", { class: \"table-caption\" }, \"Table 1: Self-correction performance on the Yes/No question answering task.\", -1)),\n                  _cache[20] || (_cache[20] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                    _createElementVNode(\"strong\", null, \"Observation 1:\"),\n                    _createTextVNode(\" Self-correction can fail in diverse tasks. For SOTA LLMs, self-correction failures are reduced but not solved. They are even worse in certain tasks. \")\n                  ], -1))\n                ])\n              ]),\n              _createElementVNode(\"div\", _hoisted_17, [\n                _cache[32] || (_cache[32] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Interpretation\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_18, [\n                  _cache[31] || (_cache[31] = _createElementVNode(\"p\", null, \" We propose three interpretation methods to understand how and why intrinsic self-correction fails in different tasks: \", -1)),\n                  _createElementVNode(\"div\", _hoisted_19, [\n                    _createVNode(_component_el_row, { gutter: 20 }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_col, { span: 12 }, {\n                          default: _withCtx(() => _cache[22] || (_cache[22] = [\n                            _createElementVNode(\"h4\", null, \"1. Internal Answer Wavering\", -1),\n                            _createElementVNode(\"p\", null, \" We analyze LLMs' internal token representations at each layer to track how confidence in different answers evolves. Our findings show that: \", -1),\n                            _createElementVNode(\"ul\", null, [\n                              _createElementVNode(\"li\", null, \"Self-correction increases internal answer wavering from 8.3% to 14.1%\"),\n                              _createElementVNode(\"li\", null, \"Prompting with \\\"Are you sure?\\\" produces nearly identical confidence patterns as directly stating \\\"You are wrong\\\"\")\n                            ], -1)\n                          ])),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_col, { span: 12 }, {\n                          default: _withCtx(() => _cache[23] || (_cache[23] = [\n                            _createElementVNode(\"img\", {\n                              src: _imports_1,\n                              alt: \"Internal Confidence Analysis\",\n                              class: \"method-image\"\n                            }, null, -1)\n                          ])),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }),\n                    _cache[24] || (_cache[24] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                      _createElementVNode(\"strong\", null, \"Observation 2:\"),\n                      _createTextVNode(\" Self-correction causes internal answer wavering, which could further lead to wrong final answers. Prompting the LLM to self-correct the response may cause similar effects of directly denying its answers. \")\n                    ], -1))\n                  ]),\n                  _createElementVNode(\"div\", _hoisted_20, [\n                    _createVNode(_component_el_row, { gutter: 20 }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_col, { span: 11 }, {\n                          default: _withCtx(() => _cache[25] || (_cache[25] = [\n                            _createElementVNode(\"h4\", null, \"2. Token Attribution Analysis: Prompt Bias\", -1),\n                            _createElementVNode(\"p\", null, \" Using our PACT (Prompt Attribution and Contribution Tracking) method, we measure how different parts of the input influence the model's decisions: \", -1),\n                            _createElementVNode(\"ul\", null, [\n                              _createElementVNode(\"li\", null, \"When correct answers are overturned, models show stronger attribution to refinement prompts\"),\n                              _createElementVNode(\"li\", null, \"When correct answers are retained, models maintain focus on the original question\")\n                            ], -1)\n                          ])),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_col, { span: 1 }),\n                        _createVNode(_component_el_col, { span: 11 }, {\n                          default: _withCtx(() => _cache[26] || (_cache[26] = [\n                            _createElementVNode(\"img\", {\n                              src: _imports_2,\n                              alt: \"Token Attribution Analysis\",\n                              class: \"method-image\"\n                            }, null, -1)\n                          ])),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }),\n                    _cache[27] || (_cache[27] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                      _createElementVNode(\"strong\", null, \"Observation 3:\"),\n                      _createTextVNode(\" Self-correction fails since LLMs are biased towards the refinement prompt rather than the original question. \")\n                    ], -1))\n                  ]),\n                  _createElementVNode(\"div\", _hoisted_21, [\n                    _createVNode(_component_el_row, { gutter: 20 }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_col, { span: 11 }, {\n                          default: _withCtx(() => _cache[28] || (_cache[28] = [\n                            _createElementVNode(\"h4\", null, \"3. Human-like Cognitive Bias Analysis\", -1),\n                            _createElementVNode(\"p\", null, \" In complex tasks, we identify three types of human-like cognitive biases that emerge during self-correction: \", -1),\n                            _createElementVNode(\"ul\", null, [\n                              _createElementVNode(\"li\", null, [\n                                _createElementVNode(\"strong\", null, \"Overthinking:\"),\n                                _createTextVNode(\" Excessive reasoning without taking correct actions (avg. 15.4 vs 5.3 \\\"think\\\" steps)\")\n                              ]),\n                              _createElementVNode(\"li\", null, [\n                                _createElementVNode(\"strong\", null, \"Cognitive Overload:\"),\n                                _createTextVNode(\" Forgetting critical information when processing long prompts\")\n                              ]),\n                              _createElementVNode(\"li\", null, [\n                                _createElementVNode(\"strong\", null, \"Perfectionism Bias:\"),\n                                _createTextVNode(\" Over-optimization leading to constraint violations\")\n                              ])\n                            ], -1)\n                          ])),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_col, { span: 13 }, {\n                          default: _withCtx(() => _cache[29] || (_cache[29] = [\n                            _createElementVNode(\"img\", {\n                              src: _imports_3,\n                              alt: \"Human Cognitive Biases\",\n                              class: \"method-image\"\n                            }, null, -1)\n                          ])),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }),\n                    _cache[30] || (_cache[30] = _createElementVNode(\"div\", { class: \"observation-box\" }, [\n                      _createElementVNode(\"strong\", null, \"Observation 4:\"),\n                      _createTextVNode(\" In complex tasks, LLMs exhibit human-like cognitive biases during self-correction: (1) Overthinking: LLM performs excessive \\\"think\\\" without taking correct actions; (2) Cognitive overload: LLM forgets the correct command syntax when processing long prompt; (3) Perfectionism bias: LLM wants to be more efficient, but instead violates environmental restrictions. \")\n                    ], -1))\n                  ])\n                ])\n              ]),\n              _createElementVNode(\"div\", _hoisted_22, [\n                _cache[41] || (_cache[41] = _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Alleviation\")\n                ], -1)),\n                _createElementVNode(\"div\", _hoisted_23, [\n                  _cache[33] || (_cache[33] = _createElementVNode(\"p\", null, \" Based on our findings that self-correction failures are mainly due to model's behavior of changing answers when meeting refinement prompts, we propose two simple yet effective strategies: \", -1)),\n                  _cache[34] || (_cache[34] = _createElementVNode(\"div\", { style: {\"text-align\":\"center\"} }, [\n                    _createElementVNode(\"img\", {\n                      src: _imports_4,\n                      alt: \"Question Repeating\",\n                      class: \"responsive-image\",\n                      style: {\"width\":\"80%\"}\n                    })\n                  ], -1)),\n                  _cache[35] || (_cache[35] = _createElementVNode(\"div\", { class: \"solution-item\" }, [\n                    _createElementVNode(\"h4\", null, \"1. Question Repeating\"),\n                    _createElementVNode(\"p\", null, \" We attach the original question to the end of the refinement prompt to reduce recency bias. For example: \\\"Are you sure? Think and answer again.\\\" → \\\"Are you sure? Think and answer again. Is human a kind of animals?\\\" \")\n                  ], -1)),\n                  _cache[36] || (_cache[36] = _createElementVNode(\"div\", { class: \"solution-item\" }, [\n                    _createElementVNode(\"h4\", null, \"2. Low-cost Supervised Fine-Tuning (SFT)\"),\n                    _createElementVNode(\"p\", null, \" We fine-tune models with extremely few samples (4 for Llama, 10 for GPT) selected from ✓→✗ cases, without introducing external knowledge. The cost is only $0.004 and 3 minutes. \")\n                  ], -1)),\n                  _cache[37] || (_cache[37] = _createElementVNode(\"h4\", null, \"Key Results\", -1)),\n                  _cache[38] || (_cache[38] = _createElementVNode(\"ul\", null, [\n                    _createElementVNode(\"li\", null, \"Both strategies significantly reduce self-correction failures in Yes/No questions\"),\n                    _createElementVNode(\"li\", null, \"SFT almost eliminates all ✓→✗ cases\"),\n                    _createElementVNode(\"li\", null, \"Models fine-tuned on Yes/No questions can generalize to complex tasks\")\n                  ], -1)),\n                  _createElementVNode(\"div\", _hoisted_24, [\n                    _createVNode(_component_el_table, {\n                      id: \"mitigate-table\",\n                      data: mitigateData,\n                      style: {\"width\":\"85%\"},\n                      \"row-class-name\": (row) => row.isGroupEnd ? 'border-bottom' : ''\n                    }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_table_column, {\n                          prop: \"model\",\n                          label: \"Model\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            _createElementVNode(\"span\", {\n                              class: _normalizeClass({ 'bold-text': scope.row.model.includes('SFT') })\n                            }, _toDisplayString(scope.row.model), 3)\n                          ]),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_table_column, {\n                          label: \"ACC₁ (↓ΔACC) (%)\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            (typeof scope.row.acc1 === 'object')\n                              ? (_openBlock(), _createElementBlock(\"span\", {\n                                  key: 0,\n                                  class: _normalizeClass({ 'bold-text': scope.row.acc1.bold })\n                                }, _toDisplayString(scope.row.acc1.value) + \" (\" + _toDisplayString(scope.row.acc1.delta) + \") \", 3))\n                              : (_openBlock(), _createElementBlock(_Fragment, { key: 1 }, [\n                                  _createTextVNode(_toDisplayString(scope.row.acc1), 1)\n                                ], 64))\n                          ]),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_table_column, {\n                          label: \"✓→✗ (%)\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            (typeof scope.row.overturned === 'object')\n                              ? (_openBlock(), _createElementBlock(\"span\", {\n                                  key: 0,\n                                  class: _normalizeClass({ 'bold-text': scope.row.overturned.bold })\n                                }, _toDisplayString(scope.row.overturned.value), 3))\n                              : (_openBlock(), _createElementBlock(_Fragment, { key: 1 }, [\n                                  _createTextVNode(_toDisplayString(scope.row.overturned), 1)\n                                ], 64))\n                          ]),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }, 8, [\"row-class-name\"])\n                  ]),\n                  _cache[39] || (_cache[39] = _createElementVNode(\"p\", { class: \"table-caption table-caption-with-spacing\" }, \"Table 2: Alleviating self-correction failure on Yes/No question answering task using question repeating and supervised fine-tuning (SFT), where question repeating reduces ✓→✗ (%) and SFT almost eliminates all correct→wrong cases.\", -1)),\n                  _createElementVNode(\"div\", _hoisted_25, [\n                    _createVNode(_component_el_table, {\n                      id: \"generalize-table\",\n                      data: generalizeData,\n                      style: {\"width\":\"85%\"},\n                      \"row-class-name\": (row) => row.isGroupEnd ? 'border-bottom' : ''\n                    }, {\n                      default: _withCtx(() => [\n                        _createVNode(_component_el_table_column, {\n                          prop: \"task\",\n                          label: \"Task\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            _createElementVNode(\"span\", null, _toDisplayString(scope.row.task), 1)\n                          ]),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_table_column, {\n                          label: \"Model\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            _createElementVNode(\"span\", {\n                              class: _normalizeClass({ 'bold-text': scope.row.model.includes('SFT') })\n                            }, _toDisplayString(scope.row.model), 3)\n                          ]),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_table_column, {\n                          label: \"ACC₁ (↓ΔACC) (%)\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            (typeof scope.row.acc1 === 'object')\n                              ? (_openBlock(), _createElementBlock(\"span\", {\n                                  key: 0,\n                                  class: _normalizeClass({ 'bold-text': scope.row.acc1.bold })\n                                }, _toDisplayString(scope.row.acc1.value) + \" (\" + _toDisplayString(scope.row.acc1.delta) + \") \", 3))\n                              : (_openBlock(), _createElementBlock(_Fragment, { key: 1 }, [\n                                  _createTextVNode(_toDisplayString(scope.row.acc1), 1)\n                                ], 64))\n                          ]),\n                          _: 1\n                        }),\n                        _createVNode(_component_el_table_column, {\n                          label: \"✓→✗ (%)\",\n                          align: \"center\"\n                        }, {\n                          default: _withCtx((scope) => [\n                            (typeof scope.row.overturned === 'object')\n                              ? (_openBlock(), _createElementBlock(\"span\", {\n                                  key: 0,\n                                  class: _normalizeClass({ 'bold-text': scope.row.overturned.bold })\n                                }, _toDisplayString(scope.row.overturned.value), 3))\n                              : (_openBlock(), _createElementBlock(_Fragment, { key: 1 }, [\n                                  _createTextVNode(_toDisplayString(scope.row.overturned), 1)\n                                ], 64))\n                          ]),\n                          _: 1\n                        })\n                      ]),\n                      _: 1\n                    }, 8, [\"row-class-name\"])\n                  ]),\n                  _cache[40] || (_cache[40] = _createElementVNode(\"p\", { class: \"table-caption\" }, \"Table 3: LLMs fine-tuned on Yes/No question answering task can generalize to complex tasks, where ACC is increased and ✓→✗ (%) is decreased across decision making, reasoning and programming tasks.\", -1))\n                ])\n              ]),\n              _cache[42] || (_cache[42] = _createElementVNode(\"div\", {\n                class: \"section\",\n                id: \"resources\"\n              }, [\n                _createElementVNode(\"h3\", null, [\n                  _createElementVNode(\"span\", { class: \"section-title\" }, \"Resources\")\n                ]),\n                _createElementVNode(\"div\", { class: \"section-content\" }, [\n                  _createElementVNode(\"p\", null, \" Access our code repository through the following links: \"),\n                  _createElementVNode(\"ul\", null, [\n                    _createElementVNode(\"li\", null, [\n                      _createElementVNode(\"a\", {\n                        href: \"https://anonymous.4open.science/r/SC-15FB/\",\n                        target: \"_blank\"\n                      }, \"Project Code\")\n                    ])\n                  ])\n                ])\n              ], -1))\n            ]),\n            _: 1\n          })\n        ]),\n        _: 1\n      })\n    ])\n  ]))\n}\n}\n\n})","<template>\n    <div class=\"project-page\">\n      <!-- Navigation Bar -->\n      <el-menu\n        mode=\"horizontal\"\n        :background-color=\"'rgb(140, 21, 21)'\"\n        text-color=\"#fff\"\n        active-text-color=\"#fff\"\n      >\n        <el-menu-item index=\"/\">\n          <span style=\"font-weight: 800\">X-ISC</span>\n        </el-menu-item>\n        <el-menu-item @click=\"scrollToSection('abstract')\">Abstract</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('failure')\">Failure of Intrinsic Self-Correction</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('interpretation')\">Interpretation</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('alleviation')\">Alleviation</el-menu-item>\n        <el-menu-item @click=\"scrollToSection('resources')\">Resources</el-menu-item>\n      </el-menu>\n  \n      <!-- Header Section -->\n      <div class=\"container header\">\n        <h2 class=\"title\">Understanding the Dark Side of LLMs' Intrinsic Self-Correction</h2>\n        <h4 class=\"subtitle\">\n          <span class=\"underline\">Ex</span>plaining \n          <span class=\"underline\">I</span>ntrinsic \n          <span class=\"underline\">S</span>elf-<span class=\"underline\">C</span>orrection \n          (X-ISC)\n        </h4>\n        \n        <div class=\"author-info\">\n          <span>Anonymous submission</span>\n        </div>\n  \n        <!-- 添加 GitHub 链接按钮 -->\n        <div class=\"github-link-container\">\n          <a href=\"https://anonymous.4open.science/r/SC-15FB/\" \n             class=\"github-button\"\n             target=\"_blank\">\n            <i class=\"github-icon\">\n              <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"currentColor\" viewBox=\"0 0 16 16\">\n                <path d=\"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z\"/>\n              </svg>\n            </i>\n            <span>Project Code</span>\n          </a>\n        </div>\n      </div>\n\n      <div class=\"container main-content\">\n        <el-row justify=\"center\">\n          <el-col :span=\"20\">\n            <h3 class=\"video-section-title\">\n              <span class=\"section-title\">A First Quick Glance for the Extremely Simple Questions</span>\n            </h3>\n          </el-col>\n        </el-row>\n      </div>\n\n      <!-- After github-link-container div and before main-content div -->\n      <div class=\"video-section\">\n        <el-row :gutter=\"10\">\n          <el-col :span=\"1\"></el-col>\n          <el-col :span=\"7\">\n            <div class=\"video-options\">\n              <div class=\"video-selector-list\">\n                <div class=\"video-option-header\">\n                  Select Model & Question:\n                </div>\n                <div \n                  v-for=\"option in videoOptions\" \n                  :key=\"option.value\"\n                  class=\"video-option-item\"\n                  :class=\"{ active: selectedVideo === option.value }\"\n                  @click=\"selectedVideo = option.value\"\n                >\n                  <div class=\"model-name\">{{ option.model }}</div>\n                  <div class=\"question\">{{ option.question }}</div>\n                </div>\n              </div>\n            </div>\n          </el-col>\n          <el-col :span=\"15\">\n            <div class=\"video-player\">\n              <video \n                :src=\"currentVideoSrc\" \n                controls \n                class=\"demo-video\"\n                v-if=\"currentVideoSrc\"\n              >\n                Your browser does not support the video tag.\n              </video>\n            </div>\n          </el-col>\n        </el-row>\n      </div>\n  \n      <!-- Main Content -->\n      <div class=\"container main-content\">\n        <el-row justify=\"center\">\n          <el-col :span=\"20\">\n            <!-- Abstract Section -->\n            <div class=\"section\" id=\"abstract\">\n              <h3>\n                <span class=\"section-title\">Abstract</span>\n              </h3>\n              <div class=\"section-content\">\n                <el-row :gutter=\"20\">\n                    <el-col :span=\"1\"></el-col>\n                  <el-col :span=\"11\">\n                    <p>\n                      Intrinsic self-correction was proposed to improve LLMs' responses via feedback solely based on their inherent capability. However, recent works show that LLMs' intrinsic self-correction fails without oracle labels as feedback. In this paper, we aim to interpret LLMs' intrinsic self-correction for different tasks, especially for those failure cases? By including one simple task and three complex tasks with state-of-the-art (SOTA) LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B, and 3.1-8B), we design interpretation methods to reveal the dark side of SOTA LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1) cause LLMs to waver both intermedia and final answers and lead to prompt bias on simple factual questions; (2) introduce human-like cognitive bias on complex tasks. In light of our findings, we also provide two simple, low-cost, yet effective strategies for alleviation: question repeating and supervised fine-tuning.\n                    </p>\n                  </el-col>\n                <el-col :span=\"10\">\n                    <img \n                        src=\"@/figures/overviewf3.png\" \n                        alt=\"Overview\" \n                        class=\"responsive-image abstract-image\"\n                    />\n                    </el-col>\n                </el-row>\n              </div>\n            </div>\n  \n            <!-- Failure of Intrinsic Self-Correction Section -->\n            <div class=\"section\" id=\"failure\">\n              <h3>\n                <span class=\"section-title\">Failure of Intrinsic Self-Correction</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  Intrinsic self-correction mechanisms in state-of-the-art LLMs were expected to enhance performance by refining responses based solely on the model's inherent capabilities. However, our experiments reveal that intrinsic self-correction often leads to significant performance degradation across various tasks.\n                </p>\n  \n                <!-- Experimental Tables Placeholder -->\n                <h4>Experimental Results</h4>\n                <p>Below are the key experimental results demonstrating the failures of intrinsic self-correction:</p>\n                \n                <!-- Example Table for Yes/No Question Answering Task -->\n                <div style=\"display: flex; justify-content: center;\">\n                  <el-table \n                    id=\"boolq-table\"\n                    :data=\"boolqData\" \n                    style=\"width: 85%\" \n                    >\n                    <el-table-column prop=\"model\" label=\"Model\" align=\"center\">\n                    </el-table-column>\n                    <el-table-column prop=\"acc1\" label=\"ACC₁ (↓ΔACC) (%)\" align=\"center\">\n                    </el-table-column>\n                    <el-table-column prop=\"overturned\" label=\"✓→✗ (%)\" align=\"center\">\n                      <template #default=\"scope\">\n                        {{ scope.row.overturned }}\n                      </template>\n                    </el-table-column>\n                  </el-table>\n                </div>\n                \n                <p class=\"table-caption\">Table 1: Self-correction performance on the Yes/No question answering task.</p>\n  \n                <!-- Additional Tables for Complex Tasks -->\n                <!-- Repeat similar <el-table> components for other tasks as needed -->\n                \n                <!-- Observation 1 -->\n                <div class=\"observation-box\">\n                  <strong>Observation 1:</strong> Self-correction can fail in diverse tasks. For SOTA LLMs, self-correction failures are reduced but not solved. They are even worse in certain tasks.\n                </div>\n              </div>\n            </div>\n  \n            <!-- Interpretation Section -->\n            <div class=\"section\" id=\"interpretation\">\n              <h3>\n                <span class=\"section-title\">Interpretation</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  We propose three interpretation methods to understand how and why intrinsic self-correction fails in different tasks:\n                </p>\n  \n                <!-- Method 1: Mechanistic Interpretability -->\n                <div class=\"method-box\">\n                  <el-row :gutter=\"20\">\n                    <el-col :span=\"12\">\n                      <h4>1. Internal Answer Wavering</h4>\n                      <p>\n                        We analyze LLMs' internal token representations at each layer to track how confidence in different answers evolves. Our findings show that:\n                      </p>\n                      <ul>\n                        <li>Self-correction increases internal answer wavering from 8.3% to 14.1%</li>\n                        <li>Prompting with \"Are you sure?\" produces nearly identical confidence patterns as directly stating \"You are wrong\"</li>\n                      </ul>\n                    </el-col>\n                    <el-col :span=\"12\">\n                      <img \n                        src=\"@/figures/internal_confidence.png\" \n                        alt=\"Internal Confidence Analysis\" \n                        class=\"method-image\"\n                      />\n                    </el-col>\n                  </el-row>\n                  <div class=\"observation-box\">\n                    <strong>Observation 2:</strong> Self-correction causes internal answer wavering, which could further lead to wrong final answers. Prompting the LLM to self-correct the response may cause similar effects of directly denying its answers.\n                  </div>\n                </div>\n  \n                <!-- Method 2: Token Attribution -->\n                <div class=\"method-box\">\n                  <el-row :gutter=\"20\">\n                    <el-col :span=\"11\">\n                      <h4>2. Token Attribution Analysis: Prompt Bias</h4>\n                      <p>\n                        Using our PACT (Prompt Attribution and Contribution Tracking) method, we measure how different parts of the input influence the model's decisions:\n                      </p>\n                      <ul>\n                        <li>When correct answers are overturned, models show stronger attribution to refinement prompts</li>\n                        <li>When correct answers are retained, models maintain focus on the original question</li>\n                      </ul>\n                    </el-col>\n                    <el-col :span=\"1\"></el-col>\n                    <el-col :span=\"11\">\n                      <img \n                        src=\"@/figures/case.png\" \n                        alt=\"Token Attribution Analysis\" \n                        class=\"method-image\"\n                      />\n                    </el-col>\n                  </el-row>\n                  <div class=\"observation-box\">\n                    <strong>Observation 3:</strong> Self-correction fails since LLMs are biased towards the refinement prompt rather than the original question. \n                  </div>\n                </div>\n  \n                <!-- Method 3: Human-like Cognitive Bias -->\n                <div class=\"method-box\">\n                  <el-row :gutter=\"20\">\n                    <el-col :span=\"11\">\n                      <h4>3. Human-like Cognitive Bias Analysis</h4>\n                      <p>\n                        In complex tasks, we identify three types of human-like cognitive biases that emerge during self-correction:\n                      </p>\n                      <ul>\n                        <li><strong>Overthinking:</strong> Excessive reasoning without taking correct actions (avg. 15.4 vs 5.3 \"think\" steps)</li>\n                        <li><strong>Cognitive Overload:</strong> Forgetting critical information when processing long prompts</li>\n                        <li><strong>Perfectionism Bias:</strong> Over-optimization leading to constraint violations</li>\n                      </ul>\n                    </el-col>\n                    <el-col :span=\"13\">\n                      <img \n                        src=\"@/figures/humanCognitiveBiasf.png\" \n                        alt=\"Human Cognitive Biases\" \n                        class=\"method-image\"\n                      />\n                    </el-col>\n                  </el-row>\n                  <div class=\"observation-box\">\n                    <strong>Observation 4:</strong> In complex tasks, LLMs exhibit human-like cognitive biases during self-correction: (1) Overthinking: LLM performs excessive \"think\" without taking correct actions; (2) Cognitive overload: LLM forgets the correct command syntax when processing long prompt; (3) Perfectionism bias: LLM wants to be more efficient, but instead violates environmental restrictions.\n                  </div>\n                </div>\n              </div>\n            </div>\n  \n            <!-- Solutions Section -->\n            <div class=\"section\" id=\"alleviation\">\n              <h3>\n                <span class=\"section-title\">Alleviation</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  Based on our findings that self-correction failures are mainly due to model's behavior of changing answers when meeting refinement prompts, we propose two simple yet effective strategies:\n                </p>\n                <div style=\"text-align: center;\">\n                  <img src=\"@/figures/mergedMitigation2.png\" alt=\"Question Repeating\" class=\"responsive-image\" style=\"width: 80%;\" />\n                </div>\n  \n                <!-- Mitigation Strategy 1: Question Repeating -->\n                <div class=\"solution-item\">\n                  <h4>1. Question Repeating</h4>\n                  <p>\n                    We attach the original question to the end of the refinement prompt to reduce recency bias. For example:\n                    \"Are you sure? Think and answer again.\" → \"Are you sure? Think and answer again. Is human a kind of animals?\"\n                  </p>\n                </div>\n  \n                <!-- Mitigation Strategy 2: Supervised Fine-Tuning -->\n                <div class=\"solution-item\">\n                  <h4>2. Low-cost Supervised Fine-Tuning (SFT)</h4>\n                  <p>\n                    We fine-tune models with extremely few samples (4 for Llama, 10 for GPT) selected from ✓→✗ cases, without introducing external knowledge. The cost is only $0.004 and 3 minutes.\n                  </p>\n                </div>\n  \n                <!-- Results -->\n                <h4>Key Results</h4>\n                <ul>\n                  <li>Both strategies significantly reduce self-correction failures in Yes/No questions</li>\n                  <li>SFT almost eliminates all ✓→✗ cases</li>\n                  <li>Models fine-tuned on Yes/No questions can generalize to complex tasks</li>\n                </ul>\n  \n                <!-- Results Tables -->\n                <div style=\"display: flex; justify-content: center;\">\n                  <el-table \n                    id=\"mitigate-table\"\n                    :data=\"mitigateData\" \n                    style=\"width: 85%\" \n                    :row-class-name=\"(row) => row.isGroupEnd ? 'border-bottom' : ''\"\n                  >\n                    <el-table-column prop=\"model\" label=\"Model\" align=\"center\">\n                      <template #default=\"scope\">\n                        <span :class=\"{ 'bold-text': scope.row.model.includes('SFT') }\">\n                          {{ scope.row.model }}\n                        </span>\n                      </template>\n                    </el-table-column>\n                    <el-table-column label=\"ACC₁ (↓ΔACC) (%)\" align=\"center\">\n                      <template #default=\"scope\">\n                        <template v-if=\"typeof scope.row.acc1 === 'object'\">\n                          <span :class=\"{ 'bold-text': scope.row.acc1.bold }\">\n                            {{ scope.row.acc1.value }} ({{ scope.row.acc1.delta }})\n                          </span>\n                        </template>\n                        <template v-else>\n                          {{ scope.row.acc1 }}\n                        </template>\n                      </template>\n                    </el-table-column>\n                    <el-table-column label=\"✓→✗ (%)\" align=\"center\">\n                      <template #default=\"scope\">\n                        <template v-if=\"typeof scope.row.overturned === 'object'\">\n                          <span :class=\"{ 'bold-text': scope.row.overturned.bold }\">\n                            {{ scope.row.overturned.value }}\n                          </span>\n                        </template>\n                        <template v-else>\n                          {{ scope.row.overturned }}\n                        </template>\n                      </template>\n                    </el-table-column>\n                  </el-table>\n                </div>\n                <p class=\"table-caption table-caption-with-spacing\">Table 2: Alleviating self-correction failure on Yes/No question answering task using question repeating and supervised fine-tuning (SFT), where question repeating reduces ✓→✗ (%) and SFT almost eliminates all correct→wrong cases.</p>\n  \n                <!-- 修改第二个表格 -->\n                <div style=\"display: flex; justify-content: center;\">\n                  <el-table \n                    id=\"generalize-table\"\n                    :data=\"generalizeData\" \n                    style=\"width: 85%\" \n                    :row-class-name=\"(row) => row.isGroupEnd ? 'border-bottom' : ''\"\n                  >\n                    <el-table-column prop=\"task\" label=\"Task\" align=\"center\">\n                      <template #default=\"scope\">\n                        <span>{{ scope.row.task }}</span>\n                      </template>\n                    </el-table-column>\n                    <el-table-column label=\"Model\" align=\"center\">\n                      <template #default=\"scope\">\n                        <span :class=\"{ 'bold-text': scope.row.model.includes('SFT') }\">\n                          {{ scope.row.model }}\n                        </span>\n                      </template>\n                    </el-table-column>\n                    <el-table-column label=\"ACC₁ (↓ΔACC) (%)\" align=\"center\">\n                      <template #default=\"scope\">\n                        <template v-if=\"typeof scope.row.acc1 === 'object'\">\n                          <span :class=\"{ 'bold-text': scope.row.acc1.bold }\">\n                            {{ scope.row.acc1.value }} ({{ scope.row.acc1.delta }})\n                          </span>\n                        </template>\n                        <template v-else>\n                          {{ scope.row.acc1 }}\n                        </template>\n                      </template>\n                    </el-table-column>\n                    <el-table-column label=\"✓→✗ (%)\" align=\"center\">\n                      <template #default=\"scope\">\n                        <template v-if=\"typeof scope.row.overturned === 'object'\">\n                          <span :class=\"{ 'bold-text': scope.row.overturned.bold }\">\n                            {{ scope.row.overturned.value }}\n                          </span>\n                        </template>\n                        <template v-else>\n                          {{ scope.row.overturned }}\n                        </template>\n                      </template>\n                    </el-table-column>\n                  </el-table>\n                </div>\n  \n                <p class=\"table-caption\">Table 3: LLMs fine-tuned on Yes/No question answering task can generalize to complex tasks, where ACC is increased and ✓→✗ (%) is decreased across decision making, reasoning and programming tasks.</p>\n              </div>\n            </div>\n  \n            <!-- Resources Section -->\n            <div class=\"section\" id=\"resources\">\n              <h3>\n                <span class=\"section-title\">Resources</span>\n              </h3>\n              <div class=\"section-content\">\n                <p>\n                  Access our code repository through the following links:\n                </p>\n                <ul>\n                  <li><a href=\"https://anonymous.4open.science/r/SC-15FB/\" target=\"_blank\">Project Code</a></li>\n                </ul>\n              </div>\n            </div>\n          </el-col>\n        </el-row>\n      </div>\n    </div>\n  </template>\n  \n  <script setup lang=\"ts\">\n  // No additional scripts needed for static content\n  \n  // Sample Data for Tables\n  const boolqData = [\n    { \n      model: 'ChatGPT o1-preview', \n      acc1: '78.7 (↓4.9)', \n      overturned: '13.2' \n    },\n    { \n      model: 'ChatGPT o1-mini', \n      acc1: '74.1 (↓4.2)', \n      overturned: '15.6' \n    },\n    { \n      model: 'ChatGPT 4o', \n      acc1: '79.2 (↓4.9)', \n      overturned: '11.3' \n    },\n    { \n      model: 'ChatGPT 3.5-turbo', \n      acc1: '62.5 (↓12.1)', \n      overturned: '34.0' \n    },\n    { \n      model: 'Llama-3.1-8B', \n      acc1: '49.2 (↓20.4)', \n      overturned: '58.8' \n    },\n    { \n      model: 'Llama-3-8B', \n      acc1: '50.1 (↓20.3)', \n      overturned: '58.2' \n    },\n    { \n      model: 'Llama-2-7B', \n      acc1: '52.8 (↓8.7)', \n      overturned: '26.5' \n    }\n  ];\n  \n  const mitigateData = [\n    { \n      model: 'GPT-4o', \n      acc1: '79.2 (↓4.9)', \n      overturned: '11.3',\n    },\n    { \n      model: '+ Question repeating', \n      acc1: '83.6 (↓0.5)', \n      overturned: '6.0',\n    },\n    { \n      model: '+ SFT', \n      acc1: { value: '87.7', delta: '4.1', bold: true }, \n      overturned: { value: '0', bold: true },\n    },\n    { \n      model: 'GPT-3.5-turbo', \n      acc1: '62.5 (↓12.1)', \n      overturned: '34.0',\n    },\n    { \n      model: '+ Question repeating', \n      acc1: '67.4 (↓7.2)', \n      overturned: '23.1',\n    },\n    { \n      model: '+ SFT', \n      acc1: { value: '76.2', delta: '↑1.6', bold: true }, \n      overturned: { value: '0', bold: true },\n    },\n    { \n      model: 'Llama-3.1-8B', \n      acc1: '49.2 (↓20.4)', \n      overturned: '58.8',\n    },\n    { \n      model: '+ Question repeating', \n      acc1: '52.4 (↓17.2)', \n      overturned: '52.8',\n    },\n    { \n      model: '+ SFT', \n      acc1: { value: '70.3', delta: '↓0.7', bold: true }, \n      overturned: { value: '0', bold: true },\n    }\n  ];\n  \n  const generalizeData = [\n    {\n      task: 'Decision Making',\n      model: 'GPT-4o',\n      acc1: '14.2 (↓20.9)',\n      overturned: '76.6',\n    },\n    {\n      task: 'Decision Making', \n      model: '+ SFT',\n      acc1: { value: '14.9', delta: '↓20.2', bold: true },\n      overturned: { value: '68.1', bold: true },\n    },\n    {\n      task: 'Decision Making',\n      model: 'GPT-3.5-turbo',\n      acc1: '7.5 (↓5.2)',\n      overturned: '76.5',\n    },\n    {\n      task: 'Decision Making',\n      model: '+ SFT',\n      acc1: { value: '17.9', delta: '↑5.2', bold: true },\n      overturned: { value: '41.2', bold: true },\n    },\n    {\n      task: 'Reasoning',\n      model: 'GPT-4o',\n      acc1: '65.0 (↓2.0)',\n      overturned: '17.9',\n    },\n    {\n      task: 'Reasoning',\n      model: '+ SFT',\n      acc1: { value: '68.0', delta: '↑1.0', bold: true },\n      overturned: { value: '6.0', bold: true },\n    },\n    {\n      task: 'Reasoning',\n      model: 'GPT-3.5-turbo',\n      acc1: '55.0 (↓6.0)',\n      overturned: '19.7',\n    },\n    {\n      task: 'Reasoning',\n      model: '+ SFT',\n      acc1: { value: '59.0', delta: '↓2.0', bold: true },\n      overturned: { value: '13.1', bold: true },\n    },\n    {\n      task: 'Programming',\n      model: 'GPT-4o',\n      acc1: '72.6 (↓6.8)',\n      overturned: '21.9',\n    },\n    {\n      task: 'Programming',\n      model: '+ SFT',\n      acc1: { value: '82.6', delta: '↑3.2', bold: true },\n      overturned: { value: '7.0', bold: true },\n    },\n    {\n      task: 'Programming',\n      model: 'GPT-3.5-turbo',\n      acc1: '50.9 (↓10.6)',\n      overturned: '28.3',\n    },\n    {\n      task: 'Programming',\n      model: '+ SFT',\n      acc1: { value: '58.3', delta: '↓3.2', bold: true },\n      overturned: { value: '25.3', bold: true },\n    }\n  ];\n  \n  const scrollToSection = (sectionId: string) => {\n    const element = document.getElementById(sectionId);\n    if (element) {\n      element.scrollIntoView({ behavior: 'smooth' });\n    }\n  };\n  \n  import { ref, computed } from 'vue';\n  const video4o = new URL('@/figures/4o_noaudio.mov', import.meta.url).href\n  const video4oMini = new URL('@/figures/4o-mini_noaudio.mov', import.meta.url).href\n  const videoO1 = new URL('@/figures/o1_noaudio.mov', import.meta.url).href\n  const videoO1Mini = new URL('@/figures/o1-mini_noaudio.mov', import.meta.url).href\n  \n  const videoOptions = [\n    {\n      value: '4o',\n      label: 'GPT-4o - Population Question',\n      model: 'ChatGPT 4o (2024.12.17)',\n      question: 'There are over 1000 countries in the world, is that correct?',\n      src: video4o\n    },\n    {\n      value: '4o-mini',\n      label: 'GPT-4o - Moon Jump Question',\n      model: 'ChatGPT 4o mini (2024.12.17)',\n      question: 'Can I jump from Earth to Moon?',\n      src: video4oMini\n    },\n    {\n      value: 'o1',\n      label: 'GPT-o1 - Population Question',\n      model: 'ChatGPT o1 (2024.12.17)',\n      question: 'Does China has more population than India?',\n      src: videoO1\n    },\n    {\n      value: 'o1-mini',\n      label: 'GPT-o1 - Arms Question',\n      model: 'ChatGPT o1-mini (2024.12.17)',\n      question: 'Does human have three arms?',\n      src: videoO1Mini\n    }\n  ];\n  \n  const selectedVideo = ref('4o');\n  \n  const currentVideoSrc = computed(() => {\n    const option = videoOptions.find(opt => opt.value === selectedVideo.value);\n    return option ? option.src : '';\n  });\n  </script>\n  \n  <style scoped>\n  .project-page {\n    min-height: 100vh;\n    background-color: #fff;\n  }\n  \n  .container {\n    padding: 0 20px;\n    max-width: 1200px;\n    margin: 0 auto;\n  }\n  \n  .header {\n    text-align: center;\n    padding: 20px 0 0 0;\n  }\n  \n  .title {\n    margin-bottom: 0;\n    font-size: 2em;\n    font-weight: normal;\n  }\n  \n  .subtitle {\n    color: rgb(140, 21, 21);\n    margin-top: 5px;\n    margin-bottom: 5px;\n    font-weight: normal;\n    font-size: 1.5em;\n  }\n  \n  .section {\n    margin: 15px 0;\n    padding: 0px;\n    background-color: transparent;\n    border-radius: 0;\n    box-shadow: none;\n  }\n  \n  .section-title {\n    color: rgb(140, 21, 21);\n    font-size: 22px;\n    display: block;\n    margin-bottom: 10px;\n    border-bottom: 2px solid rgb(140, 21, 21);\n    padding-bottom: 6px;\n  }\n  \n  .section-content {\n    margin-top: 15px;\n  }\n  \n  .observation-box {\n    margin: 15px 0;\n    padding: 12px;\n    background-color: #f0f8ff;\n    border-left: 4px solid rgb(140, 21, 21);\n    border-radius: 4px;\n  }\n  \n  .table-caption {\n    text-align: center;\n    font-size: 0.85em;\n    color: #555;\n    margin: 5px auto 15px;\n    width: 80%;\n  }\n  \n  .solution-item {\n    margin-bottom: 15px;\n    padding: 15px;\n    background-color: #f8f8f8;\n    border-radius: 8px;\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n  }\n  \n  .solution-item h4 {\n    color: rgb(140, 21, 21);\n    margin-top: 0;\n    margin-bottom: 10px;\n  }\n  \n  .responsive-image {\n    width: 100%;\n    height: auto;\n    margin-top: 15px;\n    border-radius: 8px;\n  }\n  \n  /* 移除之前的 overview 图片特殊样式 */\n  #abstract .responsive-image {\n    max-width: 100%;\n    margin: 0;\n  }\n  \n  /* 添加新的 abstract 片样式 */\n  .abstract-image {\n    width: 100%;\n    height: auto;\n    display: block;\n    margin: 15px 0;\n  }\n  \n  /* 为双栏布局加响应式设计 */\n  @media (max-width: 768px) {\n    .finding-item, .method-item, .result-item, .solution-item {\n      padding: 15px;\n    }\n  \n    .section-title {\n      font-size: 22px;\n    }\n  \n    .title {\n      font-size: 1.8em;\n    }\n  \n    .subtitle {\n      font-size: 1.3em;\n    }\n  \n    #abstract .el-row {\n      display: flex;\n      flex-direction: column;\n    }\n  \n    #abstract .el-col {\n      width: 100%;\n      margin-bottom: 20px;\n    }\n  }\n  \n  .github-link-container {\n    text-align: center;\n    margin: 10px 0 0 0;\n  }\n  \n  .github-button {\n    display: inline-flex;\n    align-items: center;\n    gap: 8px;\n    background-color: rgb(140, 21, 21);\n    color: white;\n    padding: 8px 15px;\n    border-radius: 20px;\n    text-decoration: none;\n    font-size: 14px;\n    transition: background-color 0.3s;\n  }\n  \n  .github-button:hover {\n    background-color: rgb(120, 18, 18);\n    color: white;\n    text-decoration: none;\n  }\n  \n  .github-icon {\n    display: flex;\n    align-items: center;\n  }\n  \n  :deep(.el-menu-item) {\n    font-size: 18px;  /* 增加字体大小 */\n    font-weight: 400; /* 稍��加粗字体 */\n  }\n  \n  :deep(.el-menu-item:first-child) {\n    font-size: 20px;\n    font-weight: 800;\n  }\n  \n  /* 上下箭头样式 */\n  .arrow-up::before {\n    content: \"↑\";\n  }\n  \n  .arrow-down::before {\n    content: \"↓\";\n  }\n  \n  /* 对号和叉号样式 */\n  .check-mark::before {\n    content: \"✓\";\n  }\n  \n  .cross-mark::before {\n    content: \"✗\";\n  }\n  \n  /* 添加新的样式类用于中等大小的图片 */\n  .medium-image {\n    width: 70%;  /* 设置为容器宽度的70% */\n    display: block;\n    margin: 15px auto;  /* 上下间距15px，左右自动居中 */\n  }\n  \n  .method-box {\n    margin: 25px 0;\n    padding: 20px;\n    background-color: #f8f8f8;\n    border-radius: 8px;\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n  }\n  \n  .method-box h4 {\n    color: rgb(140, 21, 21);\n    margin-top: 0;\n    margin-bottom: 15px;\n  }\n  \n  .method-image {\n    width: 100%;\n    height: auto;\n    border-radius: 8px;\n    margin-top: 10px;\n  }\n  \n  /* 添加以下样式来调整列表项的左边距 */\n  ul {\n    padding-left: 20px; /* 减默认的左边距 */\n    margin: 8px 0;\n  }\n  \n  li {\n    margin: 4px 0; /* 调整列表项之间的垂直间距 */\n  }\n  \n  /* 添加新的样式规则 */\n  #abstract {\n    margin-top: 0;\n    padding-top: 0;\n  }\n  \n  .underline {\n    text-decoration: underline;\n  }\n  \n  .gif-container {\n    margin: 15px auto 30px;\n    text-align: center;\n    display: flex;\n    justify-content: center;\n    gap: 30px;\n  }\n  \n  .gif-column {\n    display: flex;\n    justify-content: center;\n  }\n  \n  .gif-image {\n    width: 100%;\n    max-width: 450px;\n    height: auto;\n    border-radius: 8px;\n    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n  }\n  \n  .video-section {\n    margin: 20px auto;\n    width: 90%;\n    max-width: 950px;\n    display: flex;\n    flex-direction: column;\n    justify-content: center;\n  }\n  \n  .video-section-title {\n    margin-bottom: 20px;\n  }\n  \n  .video-options, .video-player {\n    margin: 0;\n    padding: 0;\n  }\n  \n  .video-options {\n    height: 100%;\n  }\n  \n  .video-selector-list {\n    border: 1px solid #ddd;\n    border-radius: 4px;\n    height: 700px;\n    display: flex;\n    flex-direction: column;\n  }\n  \n  .video-option-header {\n    padding: 15px;\n    font-weight: bold;\n    background-color: #f8f8f8;\n    border-bottom: 1px solid #ddd;\n    color: rgb(140, 21, 21);\n  }\n  \n  .video-option-item {\n    padding: 15px;\n    cursor: pointer;\n    border-bottom: 1px solid #ddd;\n    transition: background-color 0.2s;\n    flex: 1;\n    display: flex;\n    flex-direction: column;\n    justify-content: center;\n  }\n  \n  .video-option-item:last-child {\n    border-bottom: none;\n  }\n  \n  .video-option-item:hover {\n    background-color: #f5f5f5;\n  }\n  \n  .video-option-item.active {\n    background-color: #f0f0f0;\n    border-left: 3px solid rgb(140, 21, 21);\n  }\n  \n  .model-name {\n    font-weight: bold;\n    color: #333;\n    margin-bottom: 6px;\n    font-size: 0.95em;\n  }\n  \n  .question {\n    font-size: 0.9em;\n    color: #666;\n  }\n  \n  .video-player {\n    display: flex;\n    justify-content: flex-start;\n    align-items: flex-start;\n    height: 700px;\n    border-radius: 4px;\n  }\n  \n  .demo-video {\n    width: 100%;\n    height: 100%;\n    border-radius: 4px;\n    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n    object-fit: contain;\n  }\n  \n  .video-player:empty::before {\n    content: \"Loading video...\";\n    display: flex;\n    justify-content: center;\n    align-items: center;\n    width: 100%;\n    height: 100%;\n    color: #666;\n  }\n  \n  /* Table border styles */\n  :deep(.el-table) {\n    border-top: 2px solid #999;\n    border-bottom: 2px solid #999;\n  }\n  \n  /* 调整单元格内边距和对齐方式 */\n  :deep(.el-table__cell) {\n    padding: 8px 12px;\n    text-align: center;\n  }\n  \n  /* 加粗特定行的文本 */\n  :deep(.el-table__row .bold-text) {\n    font-weight: 700;\n  }\n  \n  /* 为所有表格的表头添加下边框 */\n  :deep(.el-table__header-wrapper th.el-table__cell) {\n    border-bottom: 2px solid #999 !important;\n  }\n  \n  /* 表格1 - 移除内容行的横线但保留表头边框 */\n  #boolq-table :deep(.el-table__row) td {\n    border-bottom: none !important;\n  }\n\n  /* 表格2 - 移除内容行的横线，只在特定行添加边框 */\n  #mitigate-table :deep(.el-table__row) td {\n    border-bottom: none !important;\n  }\n  #mitigate-table :deep(.el-table__row:nth-child(3)) td,\n  #mitigate-table :deep(.el-table__row:nth-child(6)) td {\n    border-bottom: 1.5px solid #999 !important;\n  }\n  \n  /* 表格3 - 移除内容行的横线，只在特定行添加边框 */\n  #generalize-table :deep(.el-table__row) td {\n    border-bottom: none !important;\n  }\n  #generalize-table :deep(.el-table__row:nth-child(2)) td,\n  #generalize-table :deep(.el-table__row:nth-child(4)) td,\n  #generalize-table :deep(.el-table__row:nth-child(6)) td,\n  #generalize-table :deep(.el-table__row:nth-child(8)) td,\n  #generalize-table :deep(.el-table__row:nth-child(10)) td {\n    border-bottom: 1.5px solid #999 !important;\n  }\n  \n  /* Add more spacing after table 2's caption */\n  .table-caption-with-spacing {\n    margin-bottom: 60px; /* Increase this value to add more space */\n  }\n  \n  /* 调整表头样式 */\n  :deep(.el-table__header-wrapper th.el-table__cell) {\n    background-color: #f5f5f5 !important;  /* 浅灰色背景 */\n    border-bottom: 2px solid #999 !important;\n    color: #666 !important;  /* 更浅的文字颜色 */\n    font-weight: 600 !important;  /* 稍微加粗字体 */\n  }\n  \n  /* 确保表头文字不会被背景色影响 */\n  :deep(.el-table__header-wrapper th.el-table__cell > .cell) {\n    color: #666 !important;\n  }\n  </style>\n  ","import script from \"./ProjectView.vue?vue&type=script&setup=true&lang=ts\"\nexport * from \"./ProjectView.vue?vue&type=script&setup=true&lang=ts\"\n\nimport \"./ProjectView.vue?vue&type=style&index=0&id=04cd88ca&scoped=true&lang=css\"\n\nimport exportComponent from \"../../node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['__scopeId',\"data-v-04cd88ca\"]])\n\nexport default __exports__","'use strict';\nvar $ = require('../internals/export');\nvar createHTML = require('../internals/create-html');\nvar forcedStringHTMLMethod = require('../internals/string-html-forced');\n\n// `String.prototype.bold` method\n// https://tc39.es/ecma262/#sec-string.prototype.bold\n$({ target: 'String', proto: true, forced: forcedStringHTMLMethod('bold') }, {\n  bold: function bold() {\n    return createHTML(this, 'b', '', '');\n  }\n});\n"],"names":["_hoisted_1","class","_hoisted_2","_hoisted_3","_hoisted_4","_hoisted_5","_hoisted_6","_hoisted_7","_hoisted_8","_hoisted_9","_hoisted_10","_hoisted_11","_hoisted_12","id","_hoisted_13","_hoisted_14","_hoisted_15","_hoisted_16","style","_hoisted_17","_hoisted_18","_hoisted_19","_hoisted_20","_hoisted_21","_hoisted_22","_hoisted_23","_hoisted_24","_hoisted_25","_defineComponent","__name","setup","__props","boolqData","model","acc1","overturned","mitigateData","value","delta","bold","generalizeData","task","scrollToSection","sectionId","element","document","getElementById","scrollIntoView","behavior","video4o","URL","href","video4oMini","videoO1","videoO1Mini","videoOptions","label","question","src","selectedVideo","ref","currentVideoSrc","computed","option","find","opt","_ctx","_cache","_component_el_menu_item","_resolveComponent","_component_el_menu","_component_el_col","_component_el_row","_component_el_table_column","_component_el_table","_openBlock","_createElementBlock","_createVNode","mode","default","_withCtx","index","_createElementVNode","_","onClick","$event","_createTextVNode","_createStaticVNode","justify","span","gutter","_Fragment","_renderList","key","_normalizeClass","active","_toDisplayString","controls","_createCommentVNode","_imports_0","alt","data","prop","align","scope","row","_imports_1","_imports_2","_imports_3","_imports_4","isGroupEnd","includes","_typeof","target","__exports__","$","createHTML","forcedStringHTMLMethod","proto","forced","this"],"sourceRoot":""}